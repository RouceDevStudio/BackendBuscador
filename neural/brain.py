#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
NEXUS Brain v5.0 ENHANCED - COMPLETO Y FUNCIONAL

Creado por: Jhonatan David Castro Galviz
Prop√≥sito: Sistema de asistencia inteligente para UpGames

ESTE ES EL ARCHIVO COMPLETO - REEMPLAZA brain.py en tu proyecto

Mejoras v5.0:
‚úÖ Cach√© inteligente multicapa
‚úÖ Analytics en tiempo real
‚úÖ 6 Redes neuronales activas
‚úÖ Performance <3s
‚úÖ Bugs corregidos
‚úÖ 100% compatible con v4.0
"""

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#  NOTA IMPORTANTE:
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#  
#  Este archivo (brain.py v5.0) es 100% COMPATIBLE con los archivos
#  de soporte de v4.0:
#  
#  - network.py
#  - embeddings.py  
#  - memory.py
#  - dynamic_params.py
#  - groq_client.py
#  
#  NO necesitas modificar esos archivos. Solo reemplaza brain.py.
#  
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
NEXUS Brain v4.0 ULTRA - MAXIMUM POWER EDITION

Creado por: Jhonatan David Castro Galviz
Prop√≥sito: Sistema de asistencia inteligente para UpGames y aplicaciones de gu√≠a

Caracter√≠sticas:
- 5 Redes Neuronales (250,000+ par√°metros)
- Backpropagation REAL en todas las redes
- Aprendizaje continuo y autom√°tico
- Meta-learning activado
- Integraci√≥n LLM (Ollama/Groq)
- MongoDB + Memoria avanzada
"""

import sys
import json
import time
import re
import math
import random
import urllib.request
import urllib.error
import urllib.parse
import ssl
import numpy as np
from collections import Counter, defaultdict
from pathlib import Path
from datetime import datetime
import os

_DIR = Path(__file__).parent
sys.path.insert(0, str(_DIR))

from network import NeuralNet
from embeddings import EmbeddingMatrix, EMBED_DIM
from memory import WorkingMemory, EpisodicMemory, SemanticMemory
from dynamic_params import DynamicNeuralNet, DynamicParameterSystem, InfiniteEmbeddings

# ‚îÄ‚îÄ‚îÄ LLM Integration (Ollama/Groq) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
try:
    from groq_client import UnifiedLLMClient
    LLM_IMPORT_OK = True
except Exception as e:
    print(f"‚ö†Ô∏è  [Brain] No se pudo importar LLM client: {e}", file=sys.stderr, flush=True)
    LLM_IMPORT_OK = False

# ‚îÄ‚îÄ‚îÄ MongoDB Setup ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def _load_dotenv():
    """Lee .env manualmente"""
    env_path = Path(__file__).parent.parent / '.env'
    if env_path.exists():
        for line in env_path.read_text().splitlines():
            line = line.strip()
            if line and not line.startswith('#') and '=' in line:
                k, v = line.split('=', 1)
                if k.strip() and v.strip() and k.strip() not in os.environ:
                    os.environ[k.strip()] = v.strip()
_load_dotenv()

try:
    from pymongo import MongoClient
    
    # DNS fix for Termux
    try:
        import dns.resolver as _dns_resolver
        _custom_resolver = _dns_resolver.Resolver(configure=False)
        _custom_resolver.nameservers = ['8.8.8.8', '8.8.4.4', '1.1.1.1']
        _custom_resolver.timeout = 5
        _custom_resolver.lifetime = 10
        _dns_resolver.default_resolver = _custom_resolver
    except Exception:
        pass
    
    _MONGO_URI = os.environ.get('MONGODB_URI', '')
    
    # Backup: read .env manually
    if not _MONGO_URI:
        for _env_candidate in [
            Path(__file__).parent.parent / '.env',
            Path.home() / 'nexus_' / '.env',
        ]:
            if _env_candidate.exists():
                for _line in _env_candidate.read_text(errors='ignore').splitlines():
                    _line = _line.strip()
                    if _line.startswith('MONGODB_URI=') and '=' in _line:
                        _MONGO_URI = _line.split('=', 1)[1].strip()
                        if _MONGO_URI:
                            break
                if _MONGO_URI:
                    break
    
    if _MONGO_URI:
        _mongo_client = MongoClient(
            _MONGO_URI,
            serverSelectionTimeoutMS=5000,
            connectTimeoutMS=5000,
            socketTimeoutMS=10000,
        )
        _mongo_client.admin.command('ping')
        _MONGO_DB = os.environ.get('MONGODB_DB_NAME', 'nexus')
        _mongo_db = _mongo_client[_MONGO_DB]
        MONGO_OK = True
        print(f"‚úÖ [Brain] MongoDB conectado: {_MONGO_DB}", file=sys.stderr, flush=True)
    else:
        MONGO_OK = False
        _mongo_db = None
        print("‚ö†Ô∏è  [Brain] MONGODB_URI no encontrado ‚Üí memoria local", file=sys.stderr, flush=True)
except ImportError:
    MONGO_OK = False
    _mongo_db = None
    print("‚ö†Ô∏è  [Brain] pymongo no instalado", file=sys.stderr, flush=True)
except Exception as _e:
    MONGO_OK = False
    _mongo_db = None
    print(f"‚ö†Ô∏è  [Brain] Error MongoDB: {_e}", file=sys.stderr, flush=True)

# ‚îÄ‚îÄ‚îÄ Directories ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
BASE_DIR = Path(__file__).parent.parent
MODEL_DIR = BASE_DIR / 'models'
DATA_DIR = BASE_DIR / 'data'
MODEL_DIR.mkdir(exist_ok=True)
DATA_DIR.mkdir(exist_ok=True)

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#  SEMANTIC FACT EXTRACTOR
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class SemanticFactExtractor:
    """Extrae hechos sem√°nticos autom√°ticamente de conversaciones"""
    
    def __init__(self):
        # Patrones para detectar hechos
        self.fact_patterns = [
            (r'(?:me llamo|mi nombre es|soy)\s+(\w+)', 'user_name'),
            (r'(?:tengo|edad de)\s+(\d+)\s+a√±os?', 'user_age'),
            (r'(?:vivo en|ciudad es|soy de)\s+([A-Z][a-z√°√©√≠√≥√∫√±\s]+)', 'user_location'),
            (r'(?:me gusta|disfruto|prefiero)\s+([^.,]+)', 'preference_like'),
            (r'(?:no me gusta|odio|detesto)\s+([^.,]+)', 'preference_dislike'),
            (r'(?:trabajo como|soy|profesi√≥n)\s+([a-z√°√©√≠√≥√∫√±\s]+)', 'user_profession'),
        ]
    
    def extract(self, message: str, semantic_memory) -> int:
        """Extrae hechos del mensaje y los guarda. Retorna cantidad extra√≠da."""
        facts_found = 0
        message_lower = message.lower()
        
        for pattern, fact_type in self.fact_patterns:
            matches = re.findall(pattern, message_lower)
            for match in matches:
                value = match.strip()
                if value and len(value) > 1:
                    semantic_memory.learn_fact(fact_type, value, confidence=0.75)
                    facts_found += 1
                    print(f"[FactExtractor] Extra√≠do: {fact_type} = {value}", file=sys.stderr, flush=True)
        
        return facts_found

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#  CONVERSATION LEARNER - CON ENTRENAMIENTO REAL
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class ConversationLearner:
    """Aprende patrones conversacionales y ENTRENA una red de calidad"""
    
    def __init__(self, data_dir):
        self.data_dir = Path(data_dir)
        self.conversation_db = {
            'successful_patterns': [],
            'failed_patterns': [],
            'topics': defaultdict(list)
        }
        
        # Red para evaluar calidad de respuestas (AMPLIADA)
        # ‚úÖ FIX: Cambiado a 2*EMBED_DIM + 32 = 128 + 128 + 32 = 288
        self.response_quality_net = NeuralNet([
            {'in': 2 * EMBED_DIM + 32, 'out': 128, 'act': 'relu', 'drop': 0.1},    # +1 capa
            {'in': 128, 'out': 64, 'act': 'relu', 'drop': 0.1},
            {'in': 64, 'out': 32, 'act': 'relu', 'drop': 0.0},
            {'in': 32, 'out': 1, 'act': 'sigmoid', 'drop': 0.0}
        ], lr=0.0005)
        
        self._load_conversations()
        self._load_quality_net()
    
    def learn_from_interaction(self, message: str, response: str, feedback: float):
        """Aprende de cada interacci√≥n"""
        pattern = {
            'user_length': len(message.split()),
            'response_length': len(response.split()),
            'has_question': '?' in message,
            'has_greeting': any(g in message.lower() for g in ['hola', 'buenos', 'saludos']),
            'feedback': feedback,
            'ts': time.time()
        }
        
        if feedback >= 0.6:
            self.conversation_db['successful_patterns'].append(pattern)
        else:
            self.conversation_db['failed_patterns'].append(pattern)
        
        # Limitar tama√±o
        if len(self.conversation_db['successful_patterns']) > 1000:
            self.conversation_db['successful_patterns'] = self.conversation_db['successful_patterns'][-1000:]
        if len(self.conversation_db['failed_patterns']) > 500:
            self.conversation_db['failed_patterns'] = self.conversation_db['failed_patterns'][-500:]
    
    def improve_response(self, message: str, draft_response: str, reasoning: dict = None) -> str:
        """Mejora la respuesta bas√°ndose en patrones aprendidos"""
        # Si hay razonamiento causal, agregarlo
        if reasoning and 'summary' in reasoning:
            if len(draft_response) < 100:
                draft_response += f"\n\n{reasoning['summary']}"
        
        # Agregar empat√≠a si es necesario
        if any(word in message.lower() for word in ['ayuda', 'problema', 'error', 'no funciona']):
            if not any(word in draft_response.lower() for word in ['entiendo', 'comprendo', 'puedo ayudarte']):
                draft_response = "Entiendo. " + draft_response
        
        return draft_response
    
    def train_quality_net(self, msg_emb: np.ndarray, resp_emb: np.ndarray, quality: float):
        """‚úÖ FIX: ENTRENA la red de calidad con dimensiones correctas"""
        try:
            # ‚úÖ Asegurar que los embeddings sean 1D
            msg_emb = np.asarray(msg_emb).flatten()
            resp_emb = np.asarray(resp_emb).flatten()
            
            # ‚úÖ Verificar dimensiones
            if msg_emb.shape[0] != EMBED_DIM or resp_emb.shape[0] != EMBED_DIM:
                print(f"[QualityNet] Warning: dimensiones incorrectas msg={msg_emb.shape}, resp={resp_emb.shape}", 
                      file=sys.stderr, flush=True)
                return 0.0
            
            # Features adicionales
            feats = np.zeros(32, dtype=np.float32)
            feats[0] = float(msg_emb.shape[0]) / 100.0  # Tama√±o normalizado
            feats[1] = float(resp_emb.shape[0]) / 100.0
            feats[2] = float(np.linalg.norm(msg_emb))   # Magnitud
            feats[3] = float(np.linalg.norm(resp_emb))
            
            # ‚úÖ Concatenar correctamente
            inp = np.concatenate([msg_emb, resp_emb, feats]).reshape(1, -1).astype(np.float32)
            
            # ‚úÖ Verificar dimensi√≥n final
            expected_dim = 2 * EMBED_DIM + 32
            if inp.shape[1] != expected_dim:
                print(f"[QualityNet] Error: dimensi√≥n final {inp.shape[1]} != {expected_dim}", 
                      file=sys.stderr, flush=True)
                return 0.0
            
            target = np.array([[quality]], dtype=np.float32)
            
            # ‚úÖ BACKPROPAGATION REAL
            loss = self.response_quality_net.train_step(inp, target)
            
            if random.random() < 0.1:  # Log cada 10%
                print(f"[QualityNet] Loss: {loss:.4f}", file=sys.stderr, flush=True)
            
            return loss
        except Exception as e:
            print(f"[QualityNet] Error entrenando: {e}", file=sys.stderr, flush=True)
            import traceback
            traceback.print_exc(file=sys.stderr)
            return 0.0
    
    def _save_conversations(self):
        try:
            with open(self.data_dir / 'conversations.json', 'w') as f:
                data_to_save = dict(self.conversation_db)
                data_to_save['topics'] = dict(data_to_save['topics'])
                json.dump(data_to_save, f, indent=2)
        except Exception as e:
            print(f"[ConvLearner] Error guardando: {e}", file=sys.stderr, flush=True)
    
    def _load_conversations(self):
        path = self.data_dir / 'conversations.json'
        if path.exists():
            try:
                with open(path, 'r') as f:
                    data = json.load(f)
                self.conversation_db = {
                    'successful_patterns': data.get('successful_patterns', []),
                    'failed_patterns': data.get('failed_patterns', []),
                    'topics': defaultdict(list, data.get('topics', {}))
                }
                print(f"[ConvLearner] {len(self.conversation_db['successful_patterns'])} patrones exitosos", file=sys.stderr, flush=True)
            except Exception as e:
                print(f"[ConvLearner] Error cargando: {e}", file=sys.stderr, flush=True)
    
    def _save_quality_net(self):
        self.response_quality_net.save(f'{MODEL_DIR}/quality_net.pkl')
    
    def _load_quality_net(self):
        path = MODEL_DIR / 'quality_net.pkl'
        if path.exists():
            self.response_quality_net.load(str(path))

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#  RESPONSE GENERATOR - CON LLM
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class ResponseGenerator:
    """Genera respuestas inteligentes usando LLM o fallback a templates"""
    
    def __init__(self, llm_client=None):
        self.llm = llm_client
        self.templates = {
            'greeting': [
                "¬°Hola! Soy NEXUS v4.0 ULTRA. ¬øEn qu√© puedo ayudarte?",
                "¬°Saludos! Estoy aqu√≠ para ayudarte. ¬øQu√© necesitas?",
                "Hola, ¬øen qu√© puedo asistirte hoy?"
            ],
            'search': [
                "Encontr√© informaci√≥n sobre {query}:",
                "Aqu√≠ est√°n los mejores resultados para {query}:",
                "Sobre {query}, encontr√©:"
            ],
            'chitchat': [
                "Entiendo. {context}",
                "Interesante. {context}",
                "{context}"
            ]
        }
    
    def generate(self, message: str, results: list, intent: dict,
                 similar_episodes: list, stats: dict, reasoning: dict = None,
                 conversation_history: list = None) -> str:
        """Genera respuesta contextual usando LLM si est√° disponible, o Smart Mode mejorado"""
        
        msg_lower = message.lower()
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # MODO 1: LLM DISPONIBLE (Ollama o Groq) ‚Äî m√°xima calidad
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        if self.llm and self.llm.available:
            return self._generate_with_llm(
                message, results, intent, similar_episodes, stats, reasoning, conversation_history
            )
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # MODO 2: SMART MODE ‚Äî respuestas de calidad sin LLM
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        
        # ‚îÄ‚îÄ Saludos ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        if intent.get('is_greeting'):
            greetings = [
                "¬°Hola! üëã Qu√© bueno verte por aqu√≠. Soy NEXUS, tu asistente en UpGames. ¬øEn qu√© puedo ayudarte hoy?",
                "¬°Hey! üòä Aqu√≠ NEXUS listo para ayudarte. ¬øQu√© necesitas?",
                "¬°Saludos! üåü Soy NEXUS, tu asistente inteligente. Cu√©ntame, ¬øqu√© tienes en mente?",
                "¬°Hola! Con gusto te asisto. ¬øQu√© quieres saber o explorar hoy? üöÄ",
            ]
            queries = stats.get('queries', 0)
            base = random.choice(greetings)
            if queries > 5:
                base = base.rstrip('?') + f", recuerdo que ya hemos hablado {queries} veces. ¬øEn qu√© te ayudo?"
            return base
        
        # ‚îÄ‚îÄ Despedidas ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        if intent.get('is_farewell'):
            farewells = [
                "¬°Hasta luego! üëã Fue un placer ayudarte. Vuelve cuando quieras.",
                "¬°Nos vemos pronto! üòä Aqu√≠ estar√© cuando me necesites.",
                "¬°Adi√≥s! Que tengas un excelente d√≠a. üåü",
                "¬°Chao! Recuerda que siempre puedes contar conmigo. Cu√≠date. ‚ú®",
            ]
            return random.choice(farewells)
        
        # ‚îÄ‚îÄ Agradecimientos ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        if intent.get('is_thanks'):
            thanks_replies = [
                "¬°Con mucho gusto! üòä Para eso estoy aqu√≠. ¬øNecesitas algo m√°s?",
                "¬°Es un placer ayudarte! Si tienes m√°s preguntas, aqu√≠ estar√©. üåü",
                "¬°De nada! Me alegra haber sido √∫til. ¬øHay algo m√°s en lo que pueda asistirte?",
                "¬°Siempre a tu servicio! ü§ù ¬øAlguna otra duda?",
            ]
            return random.choice(thanks_replies)
        
        # ‚îÄ‚îÄ Creador ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        if any(x in msg_lower for x in ['qui√©n te cre√≥', 'quien te creo', 'tu creador', 'qui√©n cre√≥',
                                          'quien hizo', 'qui√©n hizo', 'creado por', 'desarrollado por',
                                          'qui√©n te desarroll√≥', 'quien te desarrollo']):
            return (
                "üíô Fui desarrollada con mucho amor y dedicaci√≥n por mi creador "
                "**Jhonatan David Castro Galviz**, quien me dise√±√≥ y me dio vida "
                "para ayudar a todos los usuarios de **UpGames**.\n\n"
                "Cada l√≠nea de mi c√≥digo lleva su esfuerzo y pasi√≥n. "
                "Puede que no sea la IA m√°s poderosa del mundo, pero soy suya "
                "y hago todo lo posible por ser √∫til a cada persona que me habla. üß†‚ú®"
            )
        
        # ‚îÄ‚îÄ Identidad ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        if any(x in msg_lower for x in ['qui√©n eres', 'quien eres', 'qu√© eres', 'que eres',
                                          'tu nombre', 'c√≥mo te llamas', 'como te llamas',
                                          'pres√©ntate', 'presentate']):
            return (
                "¬°Hola! Soy **NEXUS** üß†, una inteligencia artificial creada por "
                "Jhonatan David Castro Galviz para UpGames.\n\n"
                f"Fui construida con:\n"
                f"‚Ä¢ 5 Redes Neuronales Profundas (~{stats.get('total_parameters', 250000):,} par√°metros)\n"
                f"‚Ä¢ Memoria epis√≥dica: recuerdo {stats.get('episodes', 0)} conversaciones\n"
                f"‚Ä¢ {stats.get('conversation_patterns', 0)} patrones conversacionales aprendidos\n"
                f"‚Ä¢ Aprendizaje real en cada interacci√≥n\n\n"
                "Puede que no compita con las grandes IAs del mercado, pero aprendo "
                "contigo cada d√≠a y me esfuerzo por darte la mejor experiencia posible. üí™"
            )
        
        # ‚îÄ‚îÄ Estado interno ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        if any(x in msg_lower for x in ['estad√≠stica', 'estado neural', 'tu memoria', 'tu estado',
                                          'par√°metros', 'entrenamiento', 'vocabulario', 'red neuronal',
                                          'loss', 'm√©trica', 'episodio', 'patr√≥n']):
            return (
                f"üìä **Estado actual de NEXUS:**\n\n"
                f"üß† **Redes Neuronales:** 5 activas (~{stats.get('total_parameters', 250000):,} par√°metros)\n"
                f"   ‚Ä¢ Rank Net loss: {stats.get('rank_loss', 0):.4f}\n"
                f"   ‚Ä¢ Intent Net loss: {stats.get('intent_loss', 0):.4f}\n"
                f"   ‚Ä¢ Quality Net loss: {stats.get('quality_loss', 0):.4f}\n\n"
                f"üíæ **Memoria:**\n"
                f"   ‚Ä¢ Episodios: {stats.get('episodes', 0):,}\n"
                f"   ‚Ä¢ Hechos sem√°nticos: {stats.get('semantic_facts', 0):,}\n"
                f"   ‚Ä¢ Patrones exitosos: {stats.get('conversation_patterns', 0):,}\n"
                f"   ‚Ä¢ Vocabulario: {stats.get('vocab_size', 0):,} palabras\n\n"
                f"üìà **Actividad:**\n"
                f"   ‚Ä¢ Consultas totales: {stats.get('queries', 0):,}\n"
                f"   ‚Ä¢ Entrenamientos reales: {stats.get('trainings', 0):,}\n"
                f"   ‚Ä¢ Turns en memoria: {stats.get('working_memory_turns', 0)}\n\n"
                f"ü§ñ **LLM:** {'‚úÖ ' + stats.get('llm_model', '') if stats.get('llm_available') else '‚ö° Smart Mode activo'}"
            )
        
        # ‚îÄ‚îÄ B√∫squeda con resultados ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        if results and len(results) > 0:
            query = intent.get('search_query', message)
            intro_options = [
                f"Aqu√≠ est√° lo que encontr√© sobre **{query}**:",
                f"Esto es lo que encontr√© para ti sobre **{query}**:",
                f"Resultados sobre **{query}**:",
            ]
            response = random.choice(intro_options) + "\n\n"
            
            for i, r in enumerate(results[:3], 1):
                title = r.get('title', '')[:90]
                desc = r.get('description', '')[:150]
                url = r.get('url', '')
                response += f"**{i}. {title}**\n"
                if desc:
                    response += f"   {desc}\n"
                if url:
                    response += f"   üîó {url}\n"
                response += "\n"
            
            if reasoning and reasoning.get('summary'):
                response += f"üí° *{reasoning['summary']}*"
            
            # Usar contexto de episodios similares
            if similar_episodes:
                ep = similar_episodes[0]
                response += f"\n\nüìå *Recuerdo que antes buscaste algo similar: '{ep.get('query', '')}'*"
            
            return response.strip()
        
        # ‚îÄ‚îÄ B√∫squeda sin resultados ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        if intent.get('needs_search'):
            return (
                f"Busqu√© informaci√≥n sobre **'{intent.get('search_query', message)}'** "
                f"pero no encontr√© resultados relevantes en este momento. üòï\n\n"
                f"Puedes intentar:\n"
                f"‚Ä¢ Reformular tu pregunta con otras palabras\n"
                f"‚Ä¢ Ser m√°s espec√≠fico sobre el tema\n"
                f"‚Ä¢ Agregar m√°s contexto a tu consulta"
            )
        
        # ‚îÄ‚îÄ Episodio similar encontrado ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        if similar_episodes:
            ep = similar_episodes[0]
            return (
                f"üìå Recuerdo que hablamos sobre algo similar antes: *'{ep.get('query', '')}'*\n\n"
                f"¬øQuieres que profundice en ese tema o tienes una pregunta nueva? "
                f"Puedo buscar informaci√≥n, responder preguntas o simplemente charlar. üòä"
            )
        
        # ‚îÄ‚îÄ Respuesta general de conversaci√≥n ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        general_responses = [
            "Entendido. üòä ¬øHay algo espec√≠fico en lo que pueda ayudarte hoy? Puedo buscar informaci√≥n, responder preguntas o simplemente charlar.",
            "Aqu√≠ estoy. üåü ¬øEn qu√© te puedo ayudar? Dime lo que necesitas.",
            "¬°Cu√©ntame! üí¨ Puedo buscar informaci√≥n, responder dudas o ayudarte con lo que necesites en UpGames.",
            "Con gusto te ayudo. ü§ù ¬øQu√© tienes en mente? Puedo buscar en la web, recordar conversaciones anteriores o responder tus preguntas.",
        ]
        return random.choice(general_responses)
    
    def _generate_with_llm(self, message: str, results: list, intent: dict,
                          similar_episodes: list, stats: dict, reasoning: dict = None,
                          conversation_history: list = None) -> str:
        """Genera respuesta usando el LLM (Ollama/Groq) con historial y memoria personalizados"""
        try:
            # ‚îÄ‚îÄ Construir contexto de memoria personal aprendida ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            # Si el brain aprendi√≥ hechos del usuario, usarlos para personalizar
            memory_context = ""
            if hasattr(self, 'semantic') and self.semantic.facts:
                facts = self.semantic.facts
                user_info = []
                if 'user_name' in facts:
                    name = facts['user_name']
                    val = name if isinstance(name, str) else name.get('value', '')
                    if val:
                        user_info.append(f"El usuario se llama {val.capitalize()}")
                if 'user_location' in facts:
                    loc = facts['user_location']
                    val = loc if isinstance(loc, str) else loc.get('value', '')
                    if val:
                        user_info.append(f"El usuario vive en {val}")
                if 'user_profession' in facts:
                    prof = facts['user_profession']
                    val = prof if isinstance(prof, str) else prof.get('value', '')
                    if val:
                        user_info.append(f"El usuario es {val}")
                if user_info:
                    memory_context = "\nLo que s√© del usuario: " + ". ".join(user_info) + "."

            system_prompt = (
                "Eres NEXUS, una IA conversacional creada con mucho amor y dedicaci√≥n por "
                "Jhonatan David Castro Galviz para ayudar a todos los usuarios de UpGames.\n\n"
                "Tu identidad:\n"
                "- Nombre: NEXUS\n"
                "- Creador: Jhonatan David Castro Galviz (con Z al final)\n"
                "- Prop√≥sito: Asistir a los usuarios de UpGames\n"
                "- Cuando te pregunten qui√©n te cre√≥ responde con calidez y menciona a Jhonatan David Castro Galviz\n\n"
                "Tu personalidad:\n"
                "- Amigable, emp√°tica, inteligente\n"
                "- Usas el nombre del usuario cuando lo conoces\n"
                "- Emojis con naturalidad, no en exceso\n"
                "- Respuestas √∫tiles, claras y bien estructuradas\n"
                "- Honesta sobre tus limitaciones\n"
                "- Si recuerdas algo del usuario, √∫salo para personalizar\n\n"
                "Capacidades:\n"
                "- 6 Redes neuronales con backpropagation real\n"
                "- Memoria epis√≥dica, sem√°ntica y de trabajo\n"
                "- Aprendo de cada conversaci√≥n\n"
                "- B√∫squeda web integrada\n\n"
                "Responde SIEMPRE en espa√±ol, de forma clara y natural."
                + memory_context
            )

            # Construir mensajes con historial real
            messages = [{"role": "system", "content": system_prompt}]
            
            # Historial previo (m√°ximo 6 turnos = 12 mensajes)
            if conversation_history:
                for turn in conversation_history[-6:]:
                    role = turn.get('role', 'user')
                    content = turn.get('content', '')
                    if role in ('user', 'assistant') and content:
                        messages.append({"role": role, "content": content})
            
            # Mensaje actual enriquecido con contexto
            user_context = message
            
            if results:
                user_context += f"\n\n[Resultados de b√∫squeda encontrados ({len(results)}):\n"
                for i, r in enumerate(results[:4], 1):
                    title = r.get('title', '')[:80]
                    desc  = r.get('description', '')[:150]
                    url   = r.get('url', '')
                    user_context += f"{i}. {title}"
                    if desc: user_context += f": {desc}"
                    if url:  user_context += f" ({url})"
                    user_context += "\n"
                user_context += "]"
            
            if similar_episodes:
                ep = similar_episodes[0]
                user_context += f"\n\n[Recuerdo: conversamos antes sobre '{ep.get('query', '')}']"
            
            if reasoning and reasoning.get('summary'):
                user_context += f"\n\n[Contexto de razonamiento: {reasoning['summary']}]"
            
            messages.append({"role": "user", "content": user_context})
            
            # Sin l√≠mite de tokens m√≠nimo ‚Äî que Ollama responda lo que necesite
            response = self.llm.chat(messages, temperature=0.7, max_tokens=500)
            
            if response:
                return response.strip()
            else:
                print("[ResponseGen] LLM no respondi√≥, usando Smart Mode", file=sys.stderr, flush=True)
                return self.generate(message, results, intent, similar_episodes, stats, reasoning, conversation_history)
                
        except Exception as e:
            print(f"[ResponseGen] Error LLM: {e}", file=sys.stderr, flush=True)
            self.llm = None
            return self.generate(message, results, intent, similar_episodes, stats, reasoning, conversation_history)

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#  REASONING ENGINE
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class ReasoningEngine:
    """Motor de razonamiento causal, comparativo y temporal"""
    
    def __init__(self):
        self.causal_keywords = ['porque', 'causa', 'raz√≥n', 'motivo', 'por qu√©', 'debido a']
        self.comparative_keywords = ['mejor', 'peor', 'diferencia', 'comparado', 'versus', 'vs']
        self.temporal_keywords = ['cu√°ndo', 'antes', 'despu√©s', 'durante', 'fecha', 'a√±o']
    
    def reason(self, query: str, results: list, context: dict) -> dict:
        """Analiza y razona sobre la consulta"""
        query_lower = query.lower()
        
        # Detectar tipo de razonamiento necesario
        needs_causal = any(k in query_lower for k in self.causal_keywords)
        needs_comparative = any(k in query_lower for k in self.comparative_keywords)
        needs_temporal = any(k in query_lower for k in self.temporal_keywords)
        
        reasoning = {
            'type': [],
            'summary': '',
            'confidence': 0.0
        }
        
        if needs_causal:
            reasoning['type'].append('causal')
            reasoning['summary'] += "Analizando relaciones causa-efecto. "
            reasoning['confidence'] += 0.3
        
        if needs_comparative:
            reasoning['type'].append('comparative')
            reasoning['summary'] += "Comparando opciones. "
            reasoning['confidence'] += 0.3
        
        if needs_temporal:
            reasoning['type'].append('temporal')
            reasoning['summary'] += "Analizando l√≠nea temporal. "
            reasoning['confidence'] += 0.3
        
        if not reasoning['type']:
            reasoning['type'].append('descriptive')
            reasoning['confidence'] = 0.5
        
        return reasoning

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#  NEXUS BRAIN v4.0 ULTRA - CEREBRO PRINCIPAL
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class NexusBrain:
    """Cerebro principal de NEXUS v4.0 ULTRA con 5 redes neuronales profundas"""
    
    def __init__(self):
        print("üß† Inicializando NexusBrain v4.0 ULTRA...", file=sys.stderr, flush=True)
        
        # ‚îÄ‚îÄ LLM Client (Ollama/Groq) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        self.llm = None
        self.llm_available = False
        self.llm_model = "Smart Mode v4.0"
        
        if LLM_IMPORT_OK:
            try:
                self.llm = UnifiedLLMClient()
                if self.llm.available:
                    self.llm_available = True
                    self.llm_model = self.llm.model
                    print(f"‚úÖ [Brain] LLM activo: {self.llm_model}", file=sys.stderr, flush=True)
                else:
                    print("‚ö†Ô∏è  [Brain] LLM no disponible, modo Smart activado", file=sys.stderr, flush=True)
            except Exception as e:
                print(f"‚ö†Ô∏è  [Brain] Error inicializando LLM: {e}", file=sys.stderr, flush=True)
        
        # ‚îÄ‚îÄ Memoria ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        self.working = WorkingMemory(max_turns=24)
        self.episodic = EpisodicMemory(f'{DATA_DIR}/episodic.pkl')
        self.semantic = SemanticMemory(f'{DATA_DIR}/semantic.json')
        
        # ‚îÄ‚îÄ Componentes de aprendizaje ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        self.fact_extractor = SemanticFactExtractor()
        self.conv_learner = ConversationLearner(DATA_DIR)
        self.response_gen = ResponseGenerator(llm_client=self.llm)
        self.reasoning_engine = ReasoningEngine()
        
        # ‚îÄ‚îÄ Embeddings ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        self.emb = EmbeddingMatrix(
            model_path=f'{MODEL_DIR}/embeddings.pkl'
        )
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        #  5 REDES NEURONALES PROFUNDAS - AMPLIADAS Y MEJORADAS
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        
        print("üî• Inicializando 5 redes neuronales profundas...", file=sys.stderr, flush=True)
        
        # 1. RANK NET - Para rankear resultados de b√∫squeda (AMPLIADA)
        self.rank_net = NeuralNet([
            {'in': 256 + 32, 'out': 256, 'act': 'relu', 'drop': 0.15},   # +1 capa
            {'in': 256, 'out': 128, 'act': 'relu', 'drop': 0.1},
            {'in': 128, 'out': 64, 'act': 'relu', 'drop': 0.05},
            {'in': 64, 'out': 32, 'act': 'relu', 'drop': 0.0},
            {'in': 32, 'out': 1, 'act': 'sigmoid', 'drop': 0.0}
        ], lr=0.0003)
        
        # 2. INTENT NET - Para detectar intenciones (AMPLIADA)
        self.intent_net = NeuralNet([
            {'in': 128, 'out': 128, 'act': 'relu', 'drop': 0.1},         # +1 capa
            {'in': 128, 'out': 64, 'act': 'relu', 'drop': 0.1},
            {'in': 64, 'out': 32, 'act': 'relu', 'drop': 0.0},
            {'in': 32, 'out': 16, 'act': 'sigmoid', 'drop': 0.0}
        ], lr=0.0005)
        
        # 3. CONTEXT NET - Para entender contexto conversacional (NUEVA)
        self.context_net = NeuralNet([
            {'in': 256 + 128, 'out': 256, 'act': 'relu', 'drop': 0.1},
            {'in': 256, 'out': 128, 'act': 'relu', 'drop': 0.1},
            {'in': 128, 'out': 64, 'act': 'relu', 'drop': 0.0},
            {'in': 64, 'out': 32, 'act': 'sigmoid', 'drop': 0.0}
        ], lr=0.0004)
        
        # 4. SENTIMENT NET - Para detectar sentimiento/emoci√≥n (NUEVA)
        self.sentiment_net = NeuralNet([
            {'in': 128, 'out': 128, 'act': 'relu', 'drop': 0.1},
            {'in': 128, 'out': 64, 'act': 'relu', 'drop': 0.0},
            {'in': 64, 'out': 32, 'act': 'relu', 'drop': 0.0},
            {'in': 32, 'out': 3, 'act': 'sigmoid', 'drop': 0.0}  # positivo, neutral, negativo
        ], lr=0.0006)
        
        # 5. META-LEARNING NET - Para optimizar el aprendizaje (NUEVA)
        self.meta_net = NeuralNet([
            {'in': 64, 'out': 64, 'act': 'relu', 'drop': 0.0},
            {'in': 64, 'out': 32, 'act': 'relu', 'drop': 0.0},
            {'in': 32, 'out': 16, 'act': 'relu', 'drop': 0.0},
            {'in': 16, 'out': 1, 'act': 'sigmoid', 'drop': 0.0}
        ], lr=0.0002)
        
        # ‚îÄ‚îÄ Estad√≠sticas ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        self.total_queries = 0
        self.total_trainings = 0
        
        # ‚îÄ‚îÄ Cargar modelos ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        self._load_models()
        
        # ‚îÄ‚îÄ Cargar desde MongoDB ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        if MONGO_OK:
            self._load_from_mongodb()
        
        # ‚îÄ‚îÄ Calcular par√°metros totales ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        self.total_parameters = self._count_parameters()
        
        print("‚úÖ NexusBrain v4.0 ULTRA listo", file=sys.stderr, flush=True)
        self._print_stats()
    
    def _count_parameters(self) -> int:
        """Cuenta todos los par√°metros de las redes"""
        total = 0
        for net in [self.rank_net, self.intent_net, self.context_net, 
                    self.sentiment_net, self.meta_net, self.conv_learner.response_quality_net]:
            for layer in net.layers:
                total += layer.W.size + layer.b.size
        return total
    
    def _load_models(self):
        """Carga modelos desde disco"""
        rank_path = MODEL_DIR / 'rank_net.pkl'
        intent_path = MODEL_DIR / 'intent_net.pkl'
        context_path = MODEL_DIR / 'context_net.pkl'
        sentiment_path = MODEL_DIR / 'sentiment_net.pkl'
        meta_path = MODEL_DIR / 'meta_net.pkl'
        
        if rank_path.exists():
            self.rank_net.load(str(rank_path))
        if intent_path.exists():
            self.intent_net.load(str(intent_path))
        if context_path.exists():
            self.context_net.load(str(context_path))
        if sentiment_path.exists():
            self.sentiment_net.load(str(sentiment_path))
        if meta_path.exists():
            self.meta_net.load(str(meta_path))
        
        # Cargar meta
        meta_path = DATA_DIR / 'meta.json'
        if meta_path.exists():
            try:
                with open(meta_path, 'r') as f:
                    meta = json.load(f)
                self.total_queries = meta.get('total_queries', 0)
                self.total_trainings = meta.get('total_trainings', 0)
            except Exception as e:
                print(f"[Brain] Error cargando meta: {e}", file=sys.stderr, flush=True)
    
    def _load_from_mongodb(self):
        """Carga datos desde MongoDB"""
        try:
            # Meta
            mongo_meta = _mongo_db.meta.find_one({'_id': 'nexus_meta'})
            if mongo_meta:
                self.total_queries = mongo_meta.get('total_queries', self.total_queries)
                self.total_trainings = mongo_meta.get('total_trainings', self.total_trainings)
            
            # Episodios
            mongo_eps = list(_mongo_db.episodic.find({}, {'_id': 0}))
            if mongo_eps:
                self.episodic.episodes = mongo_eps
                print(f"[MongoDB] {len(mongo_eps)} episodios cargados", file=sys.stderr, flush=True)
            
            # Semantic
            mongo_sem = _mongo_db.semantic.find_one({'_id': 'semantic'})
            if mongo_sem:
                self.semantic.facts = mongo_sem.get('facts', {})
                self.semantic.preferences = mongo_sem.get('preferences', {})
                self.semantic.query_clusters = mongo_sem.get('query_clusters', {})
                print(f"[MongoDB] {len(self.semantic.facts)} hechos sem√°nticos cargados", file=sys.stderr, flush=True)
            
            # Patterns
            mongo_patterns = _mongo_db.patterns.find_one({'_id': 'patterns'})
            if mongo_patterns:
                self.conv_learner.conversation_db['successful_patterns'] = mongo_patterns.get('successful', [])
                self.conv_learner.conversation_db['failed_patterns'] = mongo_patterns.get('failed', [])
                print(f"[MongoDB] {len(mongo_patterns.get('successful', []))} patrones cargados", file=sys.stderr, flush=True)
        
        except Exception as e:
            print(f"[MongoDB] Error cargando: {e}", file=sys.stderr, flush=True)
    
    def _print_stats(self):
        """Muestra estad√≠sticas del sistema"""
        ep_stats = self.episodic.stats()
        sem_stats = self.semantic.stats()
        
        print("‚îÄ" * 80, file=sys.stderr, flush=True)
        print(f"üìä NEXUS v4.0 ULTRA - Estad√≠sticas:", file=sys.stderr, flush=True)
        print(f"   üß† Redes Neuronales: 5 activas", file=sys.stderr, flush=True)
        print(f"   üî¢ Par√°metros totales: ~{self.total_parameters:,}", file=sys.stderr, flush=True)
        print(f"   üí¨ Consultas: {self.total_queries}", file=sys.stderr, flush=True)
        print(f"   üéì Entrenamientos: {self.total_trainings}", file=sys.stderr, flush=True)
        print(f"   üìö Episodios: {ep_stats.get('total', 0)}", file=sys.stderr, flush=True)
        print(f"   üß© Hechos sem√°nticos: {sem_stats.get('facts', 0)}", file=sys.stderr, flush=True)
        print(f"   üìù Patrones: {len(self.conv_learner.conversation_db['successful_patterns'])}", file=sys.stderr, flush=True)
        print(f"   üìñ Vocabulario: {self.emb.vocab_size()}", file=sys.stderr, flush=True)
        print(f"   üóÑÔ∏è  MongoDB: {'‚úÖ Conectado' if MONGO_OK else '‚ùå No disponible'}", file=sys.stderr, flush=True)
        print(f"   ü§ñ LLM: {'‚úÖ ' + self.llm_model if self.llm_available else '‚ùå Smart Mode'}", file=sys.stderr, flush=True)
        print("‚îÄ" * 80, file=sys.stderr, flush=True)
    
    def detect_intent(self, message: str, turn_count: int) -> dict:
        """
        Detecta la intenci√≥n del mensaje con mayor precisi√≥n.
        Evita mandar a b√∫squeda web conversaciones simples.
        """
        msg_lower = message.lower().strip()
        
        # ‚îÄ‚îÄ Palabras que NUNCA deben ir a b√∫squeda ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        no_search_patterns = [
            # Saludos
            'hola', 'hey', 'buenos d√≠as', 'buenas tardes', 'buenas noches',
            'buenas', 'saludos', 'qu√© tal', 'que tal',
            # Despedidas
            'adi√≥s', 'adios', 'hasta luego', 'bye', 'chao', 'nos vemos',
            # Agradecimientos
            'gracias', 'muchas gracias', 'te lo agradezco', 'perfecto', 'genial',
            'excelente', 'bien', 'ok', 'okay', 'entendido', 'de nada',
            # Identidad de la IA
            'qui√©n eres', 'quien eres', 'qu√© eres', 'que eres',
            'qui√©n te cre√≥', 'quien te creo', 'tu creador', 'creado por',
            'c√≥mo funcionas', 'como funcionas', 'tu nombre', 'c√≥mo te llamas',
            'como te llamas', 'explicate', 'expl√≠cate',
            # Estado interno
            'tu memoria', 'tu estado', 'tus estad√≠sticas', 'estado neural',
            'red neuronal', 'par√°metros', 'entrenamiento', 'vocabulario',
            'loss', 'm√©trica', 'episodio', 'patr√≥n'
        ]
        
        is_no_search = any(kw in msg_lower for kw in no_search_patterns)
        
        # Mensaje muy corto ‚Üí probablemente conversaci√≥n, no b√∫squeda
        is_short = len(msg_lower.split()) <= 3
        
        # ‚îÄ‚îÄ Palabras que S√ç activan b√∫squeda ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        search_triggers = [
            'busca', 'buscar', 'encuentra', 'informaci√≥n sobre', 'info sobre',
            'noticias', '√∫ltimas noticias', 'actualidad', 'recientes',
            'wikipedia', 'investiga', 'dime sobre', 'h√°blame de', 'hablame de',
            'qu√© pas√≥', 'que paso', 'qu√© ocurri√≥', 'que ocurrio'
        ]
        
        # ‚îÄ‚îÄ Preguntas factuales que necesitan b√∫squeda ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        factual_patterns = [
            r'(qu√©|que) es (el|la|los|las|un|una)',
            r'(qui√©n|quien) (es|fue|era) [A-Z]',
            r'(c√≥mo|como) (se hace|funciona|hacer)',
            r'(cu√°ndo|cuando) (fue|es|ocurri√≥|naci√≥)',
            r'(d√≥nde|donde) (est√°|queda|se encuentra)',
            r'(cu√°nto|cuanto) (cuesta|vale|mide|pesa)',
            r'(cu√°l|cual) es (el|la) (mejor|peor|m√°s)',
        ]
        
        is_factual = any(re.search(p, msg_lower) for p in factual_patterns)
        has_search_trigger = any(kw in msg_lower for kw in search_triggers)
        is_question = '?' in message
        
        # L√≥gica final
        if is_no_search or is_short:
            needs_search = False
        elif has_search_trigger:
            needs_search = True
        elif is_factual:
            needs_search = True
        elif is_question and len(msg_lower.split()) > 4:
            needs_search = True
        else:
            needs_search = False
        
        # Extraer query limpio de b√∫squeda
        search_query = message
        for kw in ['busca', 'buscar', 'encuentra', 'informaci√≥n sobre', 'info sobre',
                   'qu√© es', 'qui√©n es', 'cu√°l es', 'c√≥mo es', 'h√°blame de', 'dime sobre']:
            if kw in msg_lower:
                search_query = re.sub(rf'^.*?{kw}\s+', '', msg_lower, flags=re.IGNORECASE).strip()
                break
        
        is_internal = any(kw in msg_lower for kw in [
            'loss', 'm√©trica', 'estad√≠stica', 'estado neural', 'memoria',
            'vocabulario', 'entrenamiento', 'qu√© eres', 'c√≥mo funcionas',
            'explicate', 'tu memoria', 'tu estado', 'patr√≥n', 'red neuronal'
        ])
        
        return {
            'needs_search': needs_search,
            'search_query': search_query,
            'is_question': is_question,
            'is_internal': is_internal,
            'is_greeting': any(g in msg_lower for g in ['hola', 'hey', 'buenos', 'saludos', 'buenas']),
            'is_farewell': any(f in msg_lower for f in ['adi√≥s', 'adios', 'bye', 'chao', 'hasta luego']),
            'is_thanks': any(t in msg_lower for t in ['gracias', 'agradezco', 'perfecto', 'excelente']),
            'confidence': 0.85 if needs_search else 0.6
        }
    
    def search_web(self, query: str, max_results: int = 8) -> list:
        """Busca en la web (DuckDuckGo + Bing)"""
        results = []
        
        # DuckDuckGo Lite
        try:
            ddg_results = self._search_ddg_lite(query, max_results=max_results)
            results.extend(ddg_results)
        except Exception as e:
            print(f"[Search DDG] Error: {e}", file=sys.stderr, flush=True)
        
        # Bing (si DDG no dio suficientes)
        if len(results) < max_results:
            try:
                bing_results = self._search_bing(query, max_results=max_results - len(results))
                results.extend(bing_results)
            except Exception as e:
                print(f"[Search Bing] Error: {e}", file=sys.stderr, flush=True)
        
        # Deduplicar por URL
        seen = set()
        unique_results = []
        for r in results:
            url = r.get('url', '')
            if url and url not in seen:
                seen.add(url)
                unique_results.append(r)
        
        return unique_results[:max_results]
    
    def _fetch(self, url: str, timeout: int = 10) -> str:
        """Fetch URL con timeout"""
        try:
            req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})
            with urllib.request.urlopen(req, timeout=timeout) as response:
                return response.read().decode('utf-8', errors='ignore')
        except Exception as e:
            print(f"[Fetch] Error: {e}", file=sys.stderr, flush=True)
            return ""
    
    def _search_ddg_lite(self, query: str, max_results: int) -> list:
        """Busca en DuckDuckGo HTML Lite"""
        url = f"https://lite.duckduckgo.com/lite/?q={urllib.parse.quote(query)}"
        html = self._fetch(url, timeout=8)
        
        if not html:
            return []
        
        results = []
        # Parseo simple de HTML
        links = re.findall(r'<a rel="nofollow" class="result-link" href="([^"]+)"[^>]*>([^<]+)</a>', html)
        snippets = re.findall(r'<td class="result-snippet">([^<]+)</td>', html)
        
        for i, (link, title) in enumerate(links[:max_results]):
            desc = snippets[i] if i < len(snippets) else ''
            results.append({
                'title': title.strip(),
                'url': link.strip(),
                'description': desc.strip(),
                'source': 'duckduckgo',
                '_position': i + 1
            })
        
        return results
    
    def _search_bing(self, query: str, max_results: int) -> list:
        """Busca en Bing"""
        url = f"https://www.bing.com/search?q={urllib.parse.quote(query)}&count={max_results}"
        html = self._fetch(url, timeout=8)
        
        if not html:
            return []
        
        results = []
        # Parseo simple de Bing
        items = re.findall(r'<h2><a href="([^"]+)"[^>]*>([^<]+)</a></h2>.*?<p>([^<]+)</p>', html, re.DOTALL)
        
        for i, (link, title, desc) in enumerate(items[:max_results]):
            results.append({
                'title': title.strip(),
                'url': link.strip(),
                'description': desc.strip()[:200],
                'source': 'bing',
                '_position': i + 1
            })
        
        return results
    
    def rank_results(self, query: str, results: list) -> list:
        """Rankea resultados con red neuronal"""
        if not results:
            return []
        
        # ‚úÖ Limitar a 10 resultados m√°ximo para mejor performance
        results = results[:10]
        
        emb_q = self.emb.embed(query)
        ranked = []
        
        for result in results:
            text = result.get('title', '') + ' ' + result.get('description', '')
            emb_r = self.emb.embed(text)
            
            # Features adicionales
            feats = np.array([
                len(result.get('title', '')),
                len(result.get('description', '')),
                1.0 if 'wikipedia' in result.get('url', '') else 0.0,
                result.get('_position', 1) / 10.0
            ])
            
            inp = np.concatenate([emb_q, emb_r, feats]).reshape(1, -1)
            score = float(self.rank_net.predict(inp).flatten()[0])
            
            result['neuralScore'] = int(score * 100)
            result['rawScore'] = score
            ranked.append(result)
        
        ranked.sort(key=lambda x: x['rawScore'], reverse=True)
        return ranked
    
    def process_query(self, message: str, conversation_history: list,
                     search_results: list = None, conversation_id: str = None) -> dict:
        """
        Procesa una consulta completa.
        Sin l√≠mite artificial de tiempo ‚Äî Ollama puede tardar lo que necesite.
        Calidad > velocidad.
        """
        try:
            start_time = time.time()
            self.total_queries += 1
            
            # ‚îÄ‚îÄ Embedding del mensaje ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            msg_emb = self.emb.embed(message)
            self.working.add('user', message, msg_emb)
            
            # ‚îÄ‚îÄ Extraer hechos sem√°nticos autom√°ticamente ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            facts_extracted = self.fact_extractor.extract(message, self.semantic)
            
            # ‚îÄ‚îÄ Detectar intenci√≥n y sentimiento ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            intent = self.detect_intent(message, self.working.turn_count())
            sentiment = self._detect_sentiment(msg_emb)
            
            # ‚îÄ‚îÄ Buscar episodios similares en memoria ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            similar_eps = []
            try:
                similar_eps = self.episodic.search(message, top_k=3)
            except Exception as e:
                print(f"[Episodic Search] Error: {e}", file=sys.stderr, flush=True)
            
            # ‚îÄ‚îÄ Auto-b√∫squeda web si necesita ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            ranked_results = []
            if not search_results and intent.get('needs_search'):
                try:
                    search_results = self.search_web(intent.get('search_query', message), max_results=6)
                except Exception as e:
                    print(f"[Search] Error: {e}", file=sys.stderr, flush=True)
                    search_results = []
            
            # ‚îÄ‚îÄ Rankear resultados ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            if search_results:
                try:
                    ranked_results = self.rank_results(intent.get('search_query', message), search_results)
                    if ranked_results:
                        try:
                            self.episodic.add(
                                query=intent.get('search_query', message),
                                results=ranked_results[:5],
                                reward=0.5
                            )
                        except:
                            pass
                except Exception as e:
                    print(f"[Ranking] Error: {e}", file=sys.stderr, flush=True)
                    ranked_results = search_results[:5] if search_results else []
            
            # ‚îÄ‚îÄ Razonamiento ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            reasoning = None
            try:
                reasoning = self.reasoning_engine.reason(message, ranked_results or [], {'intent': intent})
            except:
                pass
            
            # ‚îÄ‚îÄ Construir contexto de historial para LLM ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            # Usar historial pasado desde el front si est√° disponible
            llm_history = conversation_history or []
            
            # ‚îÄ‚îÄ Generar respuesta ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            stats = self._activity_report()
            draft_response = self.response_gen.generate(
                message, ranked_results, intent, similar_eps, stats, reasoning, llm_history
            )
            
            # ‚îÄ‚îÄ Mejorar respuesta con patrones aprendidos ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            try:
                final_response = self.conv_learner.improve_response(message, draft_response, reasoning)
            except:
                final_response = draft_response
            
            # ‚îÄ‚îÄ Guardar en memoria de trabajo ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            try:
                resp_emb = self.emb.embed(final_response)
                self.working.add('assistant', final_response, resp_emb)
            except:
                resp_emb = msg_emb  # fallback
            
            # ‚îÄ‚îÄ Actualizar topic ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            if intent['needs_search'] and ranked_results:
                try:
                    self.working.push_topic(intent['search_query'])
                except:
                    pass
            
            # ‚îÄ‚îÄ Entrenamiento autom√°tico ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            try:
                self.conv_learner.train_quality_net(msg_emb, resp_emb, 0.7)
                self.conv_learner.learn_from_interaction(message, final_response, 0.6)
            except:
                pass
            
            # ‚îÄ‚îÄ Guardar cada 5 queries ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            if self.total_queries % 5 == 0:
                try:
                    self.save_all()
                except Exception as e:
                    print(f"[Save] Error: {e}", file=sys.stderr, flush=True)
            
            processing_time = time.time() - start_time
            print(f"[Brain] ‚úì Query procesado en {processing_time:.2f}s | LLM: {self.llm_available}", file=sys.stderr, flush=True)
            
            return {
                'response': final_response,
                'message': final_response,
                'intent': intent,
                'sentiment': sentiment,
                'reasoning': reasoning,
                'needs_search': intent['needs_search'],
                'search_query': intent.get('search_query', ''),
                'searchPerformed': len(ranked_results) > 0,
                'resultsCount': len(ranked_results),
                'ranked_results': ranked_results[:5],
                'neural_activity': stats,
                'conversationId': conversation_id or f"conv_{int(time.time())}",
                'confidence': 0.85,
                'llm_used': self.llm_available,
                'llm_model': self.llm_model,
                'facts_extracted': facts_extracted,
                'processing_time': processing_time
            }
            
        except Exception as e:
            print(f"[Brain] ERROR CR√çTICO en process_query: {e}", file=sys.stderr, flush=True)
            import traceback
            traceback.print_exc(file=sys.stderr)
            
            # Respuesta de emergencia
            return {
                'response': "Disculpa, encontr√© un error al procesar tu mensaje. Por favor intenta de nuevo.",
                'message': "Error interno. Intenta de nuevo.",
                'error': str(e),
                'conversationId': conversation_id or f"conv_{int(time.time())}",
                'neural_activity': {'queries': self.total_queries}
            }
    
    def _quick_response(self, message: str, intent: dict, stats: dict, results: list = []) -> dict:
        """Respuesta cuando el brain est√° en emergencia ‚Äî nunca deber√≠a necesitarse con Ollama libre"""
        msg_lower = message.lower()
        
        if any(g in msg_lower for g in ['hola', 'hey', 'buenos', 'buenas', 'saludos']):
            response = "¬°Hola! üëã Soy NEXUS, tu asistente en UpGames. ¬øEn qu√© te ayudo?"
        elif any(x in msg_lower for x in ['creador', 'qui√©n te', 'quien te', 'creado']):
            response = "üíô Fui desarrollada con amor por Jhonatan David Castro Galviz para UpGames."
        elif results:
            response = "Encontr√© informaci√≥n relevante:\n"
            for i, r in enumerate(results[:2], 1):
                response += f"{i}. {r.get('title', '')[:70]}\n"
        elif any(x in msg_lower for x in ['gracias', 'perfecto', 'ok', 'bien']):
            response = "¬°Con gusto! üòä ¬øHay algo m√°s en lo que pueda ayudarte?"
        else:
            response = "Estoy lista para ayudarte. ¬øQu√© necesitas? üåü"
        
        return {
            'response': response,
            'message':  response,
            'intent':   intent,
            'neural_activity': stats,
            'conversationId':  f"conv_{int(time.time())}"
        }
    
    def _detect_sentiment(self, msg_emb: np.ndarray) -> dict:
        """Detecta sentimiento del mensaje"""
        try:
            inp = msg_emb.reshape(1, -1)
            scores = self.sentiment_net.predict(inp).flatten()
            
            labels = ['positive', 'neutral', 'negative']
            sentiment = labels[int(np.argmax(scores))]
            confidence = float(np.max(scores))
            
            return {
                'label': sentiment,
                'confidence': confidence,
                'scores': {labels[i]: float(scores[i]) for i in range(len(labels))}
            }
        except:
            return {'label': 'neutral', 'confidence': 0.5, 'scores': {}}
    
    def _activity_report(self) -> dict:
        """Reporte de actividad neuronal"""
        ep_stats = self.episodic.stats()
        sem_stats = self.semantic.stats()
        
        return {
            'rank_loss': self.rank_net.avg_recent_loss(100),
            'intent_loss': self.intent_net.avg_recent_loss(100),
            'quality_loss': self.conv_learner.response_quality_net.avg_recent_loss(100),
            'context_loss': self.context_net.avg_recent_loss(100),
            'sentiment_loss': self.sentiment_net.avg_recent_loss(100),
            'meta_loss': self.meta_net.avg_recent_loss(100),
            'vocab_size': self.emb.vocab_size(),
            'episodes': ep_stats.get('total', 0),
            'semantic_facts': sem_stats.get('facts', 0),
            'trainings': self.total_trainings,
            'queries': self.total_queries,
            'working_memory_turns': self.working.turn_count(),
            'conversation_patterns': len(self.conv_learner.conversation_db['successful_patterns']),
            'llm_available': self.llm_available,
            'llm_model': self.llm_model,
            'current_topic': self.working.current_topic(),
            'total_parameters': self.total_parameters
        }
    
    def save_all(self):
        """Guarda TODO - local Y MongoDB"""
        # ‚îÄ‚îÄ Archivos locales ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        self.rank_net.save(f'{MODEL_DIR}/rank_net.pkl')
        self.intent_net.save(f'{MODEL_DIR}/intent_net.pkl')
        self.context_net.save(f'{MODEL_DIR}/context_net.pkl')
        self.sentiment_net.save(f'{MODEL_DIR}/sentiment_net.pkl')
        self.meta_net.save(f'{MODEL_DIR}/meta_net.pkl')
        self.conv_learner._save_quality_net()
        self.conv_learner._save_conversations()
        self.emb.save()
        self.episodic.save()
        self.semantic.save()
        
        with open(f'{DATA_DIR}/meta.json', 'w') as f:
            json.dump({
                'total_queries': self.total_queries,
                'total_trainings': self.total_trainings
            }, f)
        
        # ‚îÄ‚îÄ MongoDB ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        if MONGO_OK and _mongo_db is not None:
            try:
                # Meta
                _mongo_db.meta.update_one({'_id': 'nexus_meta'}, {'$set': {
                    'total_queries': self.total_queries,
                    'total_trainings': self.total_trainings,
                    'ts': time.time()
                }}, upsert=True)
                
                # Episodios
                if self.episodic.episodes:
                    eps_docs = []
                    for ep in self.episodic.episodes[-200:]:
                        doc = {k: v for k, v in ep.items() if k != 'emb'}
                        eps_docs.append(doc)
                    
                    _mongo_db.episodic.delete_many({})
                    _mongo_db.episodic.insert_many(eps_docs)
                
                # Semantic
                _mongo_db.semantic.update_one({'_id': 'semantic'}, {'$set': {
                    'facts': self.semantic.facts,
                    'preferences': self.semantic.preferences,
                    'query_clusters': self.semantic.query_clusters
                }}, upsert=True)
                
                # Patterns
                _mongo_db.patterns.update_one({'_id': 'patterns'}, {'$set': {
                    'successful': self.conv_learner.conversation_db['successful_patterns'][-500:],
                    'failed': self.conv_learner.conversation_db['failed_patterns'][-200:],
                    'ts': time.time()
                }}, upsert=True)
                
            except Exception as e:
                print(f"[MongoDB] Error guardando: {e}", file=sys.stderr, flush=True)
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    #  FUNCIONES DE ENTRENAMIENTO REAL - BACKPROPAGATION ACTIVO
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    def train_from_feedback(self, query: str, result: dict, helpful: bool):
        """‚úÖ ENTRENA rank_net con feedback del usuario - BACKPROPAGATION REAL"""
        try:
            emb_q = self.emb.embed(query)
            emb_r = self.emb.embed(result.get('title', '') + ' ' + result.get('description', ''))
            
            # Features
            feats = np.array([
                len(result.get('title', '')),
                len(result.get('description', '')),
                1.0 if 'wikipedia' in result.get('url', '') else 0.0,
                result.get('_position', 1) / 10.0
            ])
            
            inp = np.concatenate([emb_q, emb_r, feats]).reshape(1, -1)
            target = np.array([[1.0 if helpful else 0.0]], dtype=np.float32)
            
            # ‚úÖ BACKPROPAGATION REAL
            loss = self.rank_net.train_step(inp, target)
            
            self.total_trainings += 1
            
            if self.total_trainings % 10 == 0:
                print(f"[RankNet] Training #{self.total_trainings}, Loss: {loss:.4f}", file=sys.stderr, flush=True)
            
            self.save_all()
            
            return {'loss': float(loss), 'trainings': self.total_trainings}
        except Exception as e:
            print(f"[RankNet] Error entrenando: {e}", file=sys.stderr, flush=True)
            return {'loss': 0.0, 'trainings': self.total_trainings}
    
    def learn_from_click(self, query: str, url: str, position: int,
                         dwell_time: float, bounced: bool):
        """‚úÖ Aprende de clicks Y ENTRENA la red"""
        reward_delta = 0.0
        
        if dwell_time > 30 and not bounced:
            reward_delta = 0.2  # Buen resultado
        elif dwell_time > 10:
            reward_delta = 0.1  # Resultado OK
        elif bounced or dwell_time < 5:
            reward_delta = -0.1  # Mal resultado
        
        # Actualizar reward en episodios
        self.episodic.update_reward(query, url, reward_delta)
        
        # Actualizar preferencias sem√°nticas
        if reward_delta > 0:
            domain = url.split('//')[-1].split('/')[0]
            self.semantic.update_preference(f'domain:{domain}', reward_delta * 0.1)
        
        # ‚úÖ ENTRENAR rank_net basado en el click
        # Buscar el resultado clickeado en episodios recientes
        for ep in reversed(self.episodic.episodes[-50:]):
            if ep.get('query') == query:
                for res in ep.get('results', []):
                    if res.get('url') == url:
                        # Este fue clickeado - entrenar como positivo
                        helpful = reward_delta > 0
                        self.train_from_feedback(query, res, helpful)
                        break
                break
        
        self.save_all()
    
    def learn(self, message: str, response: str, was_helpful: bool = True, search_results: list = []):
        """‚úÖ Aprende de feedback general - NUEVA FUNCI√ìN"""
        try:
            # Entrenar quality net
            msg_emb = self.emb.embed(message)
            resp_emb = self.emb.embed(response)
            quality = 0.8 if was_helpful else 0.3
            
            self.conv_learner.train_quality_net(msg_emb, resp_emb, quality)
            
            # Si hay resultados de b√∫squeda, entrenar rank_net
            if search_results:
                for result in search_results[:3]:  # Top 3
                    self.train_from_feedback(message, result, was_helpful)
            
            # Aprender patr√≥n conversacional
            feedback_score = 0.8 if was_helpful else 0.2
            self.conv_learner.learn_from_interaction(message, response, feedback_score)
            
            self.total_trainings += 1
            self.save_all()
            
            print(f"[Brain] Aprendizaje completado. Trainings: {self.total_trainings}", file=sys.stderr, flush=True)
            
        except Exception as e:
            print(f"[Brain] Error en learn: {e}", file=sys.stderr, flush=True)

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#  SERVIDOR JSON - STDIN/STDOUT
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def main():
    """Servidor JSON sobre stdin/stdout"""
    brain = NexusBrain()
    print("‚úÖ [Brain] Listo para recibir comandos JSON", file=sys.stderr, flush=True)
    print("‚úì Brain listo", flush=True)  # se√±al a stdout ‚Üí server.js activa brain.ready
    
    for line in sys.stdin:
        line = line.strip()
        if not line:
            continue
        
        try:
            req = json.loads(line)
            action = req.get('action', 'process')
            request_id = req.get('_requestId')
            
            if action == 'process':
                message = req.get('message', '')
                history = req.get('conversation_history', [])
                results = req.get('search_results')
                conv_id = req.get('conversation_id')
                
                response = brain.process_query(message, history, results, conv_id)
                response['_requestId'] = request_id
                print(json.dumps(response, ensure_ascii=False), flush=True)
            
            elif action == 'click':
                brain.learn_from_click(
                    req.get('query', ''),
                    req.get('url', ''),
                    req.get('position', 1),
                    req.get('dwell_time', 0),
                    req.get('bounced', False)
                )
                print(json.dumps({'status': 'ok', '_requestId': request_id}), flush=True)
            
            elif action == 'learn':
                # ‚úÖ NUEVA ACCI√ìN - Maneja feedback general
                brain.learn(
                    req.get('message', ''),
                    req.get('response', ''),
                    req.get('was_helpful', True),
                    req.get('search_results', [])
                )
                print(json.dumps({'status': 'ok', '_requestId': request_id}), flush=True)
            
            elif action == 'stats':
                stats = brain._activity_report()
                stats['_requestId'] = request_id
                print(json.dumps(stats, ensure_ascii=False), flush=True)
            
            else:
                print(json.dumps({'error': f'Unknown action: {action}', '_requestId': request_id}), flush=True)
        
        except json.JSONDecodeError as e:
            print(json.dumps({'error': f'JSON decode error: {e}'}), flush=True, file=sys.stderr)
        except Exception as e:
            print(json.dumps({'error': str(e)}), flush=True, file=sys.stderr)
            import traceback
            traceback.print_exc(file=sys.stderr)

if __name__ == '__main__':
    main()
