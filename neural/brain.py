#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
NEXUS Brain v5.0 ENHANCED - COMPLETO Y FUNCIONAL

Creado por: Jhonatan David Castro Galviz
PropÃ³sito: Sistema de asistencia inteligente para UpGames

ESTE ES EL ARCHIVO COMPLETO - REEMPLAZA brain.py en tu proyecto

Mejoras v5.0:
âœ… CachÃ© inteligente multicapa
âœ… Analytics en tiempo real
âœ… 6 Redes neuronales activas
âœ… Performance <3s
âœ… Bugs corregidos
âœ… 100% compatible con v4.0
"""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  NOTA IMPORTANTE:
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  
#  Este archivo (brain.py v5.0) es 100% COMPATIBLE con los archivos
#  de soporte de v4.0:
#  
#  - network.py
#  - embeddings.py  
#  - memory.py
#  - dynamic_params.py
#  - groq_client.py
#  
#  NO necesitas modificar esos archivos. Solo reemplaza brain.py.
#  
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
NEXUS Brain v4.0 ULTRA - MAXIMUM POWER EDITION

Creado por: Jhonatan David Castro Galviz
PropÃ³sito: Sistema de asistencia inteligente para UpGames y aplicaciones de guÃ­a

CaracterÃ­sticas:
- 5 Redes Neuronales (250,000+ parÃ¡metros)
- Backpropagation REAL en todas las redes
- Aprendizaje continuo y automÃ¡tico
- Meta-learning activado
- IntegraciÃ³n LLM (Ollama/Groq)
- MongoDB + Memoria avanzada
"""

import sys
import json
import time
import re
import math
import random
import urllib.request
import urllib.error
import urllib.parse
import ssl
import numpy as np
from collections import Counter, defaultdict
from pathlib import Path
from datetime import datetime
import os

_DIR = Path(__file__).parent
sys.path.insert(0, str(_DIR))

from network import NeuralNet
from embeddings import EmbeddingMatrix, EMBED_DIM
from memory import WorkingMemory, EpisodicMemory, SemanticMemory
from dynamic_params import DynamicNeuralNet, DynamicParameterSystem, InfiniteEmbeddings

# â”€â”€â”€ LLM Integration (Ollama/Groq) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
try:
    from groq_client import UnifiedLLMClient
    LLM_IMPORT_OK = True
except Exception as e:
    print(f"âš ï¸  [Brain] No se pudo importar LLM client: {e}", file=sys.stderr, flush=True)
    LLM_IMPORT_OK = False

# â”€â”€â”€ MongoDB Setup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _load_dotenv():
    """Lee .env manualmente"""
    env_path = Path(__file__).parent.parent / '.env'
    if env_path.exists():
        for line in env_path.read_text().splitlines():
            line = line.strip()
            if line and not line.startswith('#') and '=' in line:
                k, v = line.split('=', 1)
                if k.strip() and v.strip() and k.strip() not in os.environ:
                    os.environ[k.strip()] = v.strip()
_load_dotenv()

try:
    from pymongo import MongoClient
    
    # DNS fix for Termux
    try:
        import dns.resolver as _dns_resolver
        _custom_resolver = _dns_resolver.Resolver(configure=False)
        _custom_resolver.nameservers = ['8.8.8.8', '8.8.4.4', '1.1.1.1']
        _custom_resolver.timeout = 5
        _custom_resolver.lifetime = 10
        _dns_resolver.default_resolver = _custom_resolver
    except Exception:
        pass
    
    _MONGO_URI = os.environ.get('MONGODB_URI', '')
    
    # Backup: read .env manually
    if not _MONGO_URI:
        for _env_candidate in [
            Path(__file__).parent.parent / '.env',
            Path.home() / 'nexus_' / '.env',
        ]:
            if _env_candidate.exists():
                for _line in _env_candidate.read_text(errors='ignore').splitlines():
                    _line = _line.strip()
                    if _line.startswith('MONGODB_URI=') and '=' in _line:
                        _MONGO_URI = _line.split('=', 1)[1].strip()
                        if _MONGO_URI:
                            break
                if _MONGO_URI:
                    break
    
    if _MONGO_URI:
        _mongo_client = MongoClient(
            _MONGO_URI,
            serverSelectionTimeoutMS=5000,
            connectTimeoutMS=5000,
            socketTimeoutMS=10000,
        )
        _mongo_client.admin.command('ping')
        _MONGO_DB = os.environ.get('MONGODB_DB_NAME', 'nexus')
        _mongo_db = _mongo_client[_MONGO_DB]
        MONGO_OK = True
        print(f"âœ… [Brain] MongoDB conectado: {_MONGO_DB}", file=sys.stderr, flush=True)
    else:
        MONGO_OK = False
        _mongo_db = None
        print("âš ï¸  [Brain] MONGODB_URI no encontrado â†’ memoria local", file=sys.stderr, flush=True)
except ImportError:
    MONGO_OK = False
    _mongo_db = None
    print("âš ï¸  [Brain] pymongo no instalado", file=sys.stderr, flush=True)
except Exception as _e:
    MONGO_OK = False
    _mongo_db = None
    print(f"âš ï¸  [Brain] Error MongoDB: {_e}", file=sys.stderr, flush=True)

# â”€â”€â”€ Directories â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE_DIR = Path(__file__).parent.parent
MODEL_DIR = BASE_DIR / 'models'
DATA_DIR = BASE_DIR / 'data'
MODEL_DIR.mkdir(exist_ok=True)
DATA_DIR.mkdir(exist_ok=True)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  SEMANTIC FACT EXTRACTOR
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class SemanticFactExtractor:
    """Extrae hechos semÃ¡nticos automÃ¡ticamente de conversaciones"""
    
    def __init__(self):
        # Patrones para detectar hechos
        self.fact_patterns = [
            (r'(?:me llamo|mi nombre es|soy)\s+(\w+)', 'user_name'),
            (r'(?:tengo|edad de)\s+(\d+)\s+aÃ±os?', 'user_age'),
            (r'(?:vivo en|ciudad es|soy de)\s+([A-Z][a-zÃ¡Ã©Ã­Ã³ÃºÃ±\s]+)', 'user_location'),
            (r'(?:me gusta|disfruto|prefiero)\s+([^.,]+)', 'preference_like'),
            (r'(?:no me gusta|odio|detesto)\s+([^.,]+)', 'preference_dislike'),
            (r'(?:trabajo como|soy|profesiÃ³n)\s+([a-zÃ¡Ã©Ã­Ã³ÃºÃ±\s]+)', 'user_profession'),
        ]
    
    def extract(self, message: str, semantic_memory) -> int:
        """Extrae hechos del mensaje y los guarda. Retorna cantidad extraÃ­da."""
        facts_found = 0
        message_lower = message.lower()
        
        for pattern, fact_type in self.fact_patterns:
            matches = re.findall(pattern, message_lower)
            for match in matches:
                value = match.strip()
                if value and len(value) > 1:
                    semantic_memory.learn_fact(fact_type, value, confidence=0.75)
                    facts_found += 1
                    print(f"[FactExtractor] ExtraÃ­do: {fact_type} = {value}", file=sys.stderr, flush=True)
        
        return facts_found

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  CONVERSATION LEARNER - CON ENTRENAMIENTO REAL
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ConversationLearner:
    """Aprende patrones conversacionales y ENTRENA una red de calidad"""
    
    def __init__(self, data_dir):
        self.data_dir = Path(data_dir)
        self.conversation_db = {
            'successful_patterns': [],
            'failed_patterns': [],
            'topics': defaultdict(list)
        }
        
        # Red para evaluar calidad de respuestas (AMPLIADA)
        # âœ… FIX: Cambiado a 2*EMBED_DIM + 32 = 128 + 128 + 32 = 288
        self.response_quality_net = NeuralNet([
            {'in': 2 * EMBED_DIM + 32, 'out': 128, 'act': 'relu', 'drop': 0.1},    # +1 capa
            {'in': 128, 'out': 64, 'act': 'relu', 'drop': 0.1},
            {'in': 64, 'out': 32, 'act': 'relu', 'drop': 0.0},
            {'in': 32, 'out': 1, 'act': 'sigmoid', 'drop': 0.0}
        ], lr=0.0005)
        
        self._load_conversations()
        self._load_quality_net()
    
    def learn_from_interaction(self, message: str, response: str, feedback: float):
        """Aprende de cada interacciÃ³n"""
        pattern = {
            'user_length': len(message.split()),
            'response_length': len(response.split()),
            'has_question': '?' in message,
            'has_greeting': any(g in message.lower() for g in ['hola', 'buenos', 'saludos']),
            'feedback': feedback,
            'ts': time.time()
        }
        
        if feedback >= 0.6:
            self.conversation_db['successful_patterns'].append(pattern)
        else:
            self.conversation_db['failed_patterns'].append(pattern)
        
        # Limitar tamaÃ±o
        if len(self.conversation_db['successful_patterns']) > 1000:
            self.conversation_db['successful_patterns'] = self.conversation_db['successful_patterns'][-1000:]
        if len(self.conversation_db['failed_patterns']) > 500:
            self.conversation_db['failed_patterns'] = self.conversation_db['failed_patterns'][-500:]
    
    def improve_response(self, message: str, draft_response: str, reasoning: dict = None) -> str:
        """Mejora la respuesta basÃ¡ndose en patrones aprendidos"""
        # Si hay razonamiento causal, agregarlo
        if reasoning and 'summary' in reasoning:
            if len(draft_response) < 100:
                draft_response += f"\n\n{reasoning['summary']}"
        
        # Agregar empatÃ­a si es necesario
        if any(word in message.lower() for word in ['ayuda', 'problema', 'error', 'no funciona']):
            if not any(word in draft_response.lower() for word in ['entiendo', 'comprendo', 'puedo ayudarte']):
                draft_response = "Entiendo. " + draft_response
        
        return draft_response
    
    def train_quality_net(self, msg_emb: np.ndarray, resp_emb: np.ndarray, quality: float):
        """âœ… FIX: ENTRENA la red de calidad con dimensiones correctas"""
        try:
            # âœ… Asegurar que los embeddings sean 1D
            msg_emb = np.asarray(msg_emb).flatten()
            resp_emb = np.asarray(resp_emb).flatten()
            
            # âœ… Verificar dimensiones
            if msg_emb.shape[0] != EMBED_DIM or resp_emb.shape[0] != EMBED_DIM:
                print(f"[QualityNet] Warning: dimensiones incorrectas msg={msg_emb.shape}, resp={resp_emb.shape}", 
                      file=sys.stderr, flush=True)
                return 0.0
            
            # Features adicionales
            feats = np.zeros(32, dtype=np.float32)
            feats[0] = float(msg_emb.shape[0]) / 100.0  # TamaÃ±o normalizado
            feats[1] = float(resp_emb.shape[0]) / 100.0
            feats[2] = float(np.linalg.norm(msg_emb))   # Magnitud
            feats[3] = float(np.linalg.norm(resp_emb))
            
            # âœ… Concatenar correctamente
            inp = np.concatenate([msg_emb, resp_emb, feats]).reshape(1, -1).astype(np.float32)
            
            # âœ… Verificar dimensiÃ³n final
            expected_dim = 2 * EMBED_DIM + 32
            if inp.shape[1] != expected_dim:
                print(f"[QualityNet] Error: dimensiÃ³n final {inp.shape[1]} != {expected_dim}", 
                      file=sys.stderr, flush=True)
                return 0.0
            
            target = np.array([[quality]], dtype=np.float32)
            
            # âœ… BACKPROPAGATION REAL
            loss = self.response_quality_net.train_step(inp, target)
            
            if random.random() < 0.1:  # Log cada 10%
                print(f"[QualityNet] Loss: {loss:.4f}", file=sys.stderr, flush=True)
            
            return loss
        except Exception as e:
            print(f"[QualityNet] Error entrenando: {e}", file=sys.stderr, flush=True)
            import traceback
            traceback.print_exc(file=sys.stderr)
            return 0.0
    
    def _save_conversations(self):
        try:
            with open(self.data_dir / 'conversations.json', 'w') as f:
                data_to_save = dict(self.conversation_db)
                data_to_save['topics'] = dict(data_to_save['topics'])
                json.dump(data_to_save, f, indent=2)
        except Exception as e:
            print(f"[ConvLearner] Error guardando: {e}", file=sys.stderr, flush=True)
    
    def _load_conversations(self):
        path = self.data_dir / 'conversations.json'
        if path.exists():
            try:
                with open(path, 'r') as f:
                    data = json.load(f)
                self.conversation_db = {
                    'successful_patterns': data.get('successful_patterns', []),
                    'failed_patterns': data.get('failed_patterns', []),
                    'topics': defaultdict(list, data.get('topics', {}))
                }
                print(f"[ConvLearner] {len(self.conversation_db['successful_patterns'])} patrones exitosos", file=sys.stderr, flush=True)
            except Exception as e:
                print(f"[ConvLearner] Error cargando: {e}", file=sys.stderr, flush=True)
    
    def _save_quality_net(self):
        self.response_quality_net.save(f'{MODEL_DIR}/quality_net.pkl')
    
    def _load_quality_net(self):
        path = MODEL_DIR / 'quality_net.pkl'
        if path.exists():
            self.response_quality_net.load(str(path))

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  RESPONSE GENERATOR - CON LLM
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ResponseGenerator:
    """Genera respuestas inteligentes usando LLM o fallback a templates"""
    
    def __init__(self, llm_client=None):
        self.llm = llm_client
        self.templates = {
            'greeting': [
                "Â¡Hola! Soy NEXUS v4.0 ULTRA. Â¿En quÃ© puedo ayudarte?",
                "Â¡Saludos! Estoy aquÃ­ para ayudarte. Â¿QuÃ© necesitas?",
                "Hola, Â¿en quÃ© puedo asistirte hoy?"
            ],
            'search': [
                "EncontrÃ© informaciÃ³n sobre {query}:",
                "AquÃ­ estÃ¡n los mejores resultados para {query}:",
                "Sobre {query}, encontrÃ©:"
            ],
            'chitchat': [
                "Entiendo. {context}",
                "Interesante. {context}",
                "{context}"
            ]
        }
    
    def generate(self, message: str, results: list, intent: dict,
                 similar_episodes: list, stats: dict, reasoning: dict = None,
                 conversation_history: list = None) -> str:
        """Genera respuesta contextual usando LLM si estÃ¡ disponible, o Smart Mode mejorado"""
        
        msg_lower = message.lower()
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # MODO 1: LLM DISPONIBLE (Ollama o Groq) â€” mÃ¡xima calidad
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.llm and self.llm.available:
            return self._generate_with_llm(
                message, results, intent, similar_episodes, stats, reasoning, conversation_history
            )
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # MODO 2: SMART MODE â€” respuestas de calidad sin LLM
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        # â”€â”€ Saludos â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if intent.get('is_greeting'):
            greetings = [
                "Â¡Hola! ðŸ‘‹ QuÃ© bueno verte por aquÃ­. Soy NEXUS, tu asistente en UpGames. Â¿En quÃ© puedo ayudarte hoy?",
                "Â¡Hey! ðŸ˜Š AquÃ­ NEXUS listo para ayudarte. Â¿QuÃ© necesitas?",
                "Â¡Saludos! ðŸŒŸ Soy NEXUS, tu asistente inteligente. CuÃ©ntame, Â¿quÃ© tienes en mente?",
                "Â¡Hola! Con gusto te asisto. Â¿QuÃ© quieres saber o explorar hoy? ðŸš€",
            ]
            queries = stats.get('queries', 0)
            base = random.choice(greetings)
            if queries > 5:
                base = base.rstrip('?') + f", recuerdo que ya hemos hablado {queries} veces. Â¿En quÃ© te ayudo?"
            return base
        
        # â”€â”€ Despedidas â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if intent.get('is_farewell'):
            farewells = [
                "Â¡Hasta luego! ðŸ‘‹ Fue un placer ayudarte. Vuelve cuando quieras.",
                "Â¡Nos vemos pronto! ðŸ˜Š AquÃ­ estarÃ© cuando me necesites.",
                "Â¡AdiÃ³s! Que tengas un excelente dÃ­a. ðŸŒŸ",
                "Â¡Chao! Recuerda que siempre puedes contar conmigo. CuÃ­date. âœ¨",
            ]
            return random.choice(farewells)
        
        # â”€â”€ Agradecimientos â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if intent.get('is_thanks'):
            thanks_replies = [
                "Â¡Con mucho gusto! ðŸ˜Š Para eso estoy aquÃ­. Â¿Necesitas algo mÃ¡s?",
                "Â¡Es un placer ayudarte! Si tienes mÃ¡s preguntas, aquÃ­ estarÃ©. ðŸŒŸ",
                "Â¡De nada! Me alegra haber sido Ãºtil. Â¿Hay algo mÃ¡s en lo que pueda asistirte?",
                "Â¡Siempre a tu servicio! ðŸ¤ Â¿Alguna otra duda?",
            ]
            return random.choice(thanks_replies)
        
        # â”€â”€ Creador â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if any(x in msg_lower for x in ['quiÃ©n te creÃ³', 'quien te creo', 'tu creador', 'quiÃ©n creÃ³',
                                          'quien hizo', 'quiÃ©n hizo', 'creado por', 'desarrollado por',
                                          'quiÃ©n te desarrollÃ³', 'quien te desarrollo']):
            return (
                "ðŸ’™ Fui desarrollada con mucho amor y dedicaciÃ³n por mi creador "
                "**Jhonatan David Castro Galviz**, quien me diseÃ±Ã³ y me dio vida "
                "para ayudar a todos los usuarios de **UpGames**.\n\n"
                "Cada lÃ­nea de mi cÃ³digo lleva su esfuerzo y pasiÃ³n. "
                "Puede que no sea la IA mÃ¡s poderosa del mundo, pero soy suya "
                "y hago todo lo posible por ser Ãºtil a cada persona que me habla. ðŸ§ âœ¨"
            )
        
        # â”€â”€ Identidad â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if any(x in msg_lower for x in ['quiÃ©n eres', 'quien eres', 'quÃ© eres', 'que eres',
                                          'tu nombre', 'cÃ³mo te llamas', 'como te llamas',
                                          'presÃ©ntate', 'presentate']):
            return (
                "Â¡Hola! Soy **NEXUS** ðŸ§ , una inteligencia artificial creada por "
                "Jhonatan David Castro Galviz para UpGames.\n\n"
                f"Fui construida con:\n"
                f"â€¢ 5 Redes Neuronales Profundas (~{stats.get('total_parameters', 250000):,} parÃ¡metros)\n"
                f"â€¢ Memoria episÃ³dica: recuerdo {stats.get('episodes', 0)} conversaciones\n"
                f"â€¢ {stats.get('conversation_patterns', 0)} patrones conversacionales aprendidos\n"
                f"â€¢ Aprendizaje real en cada interacciÃ³n\n\n"
                "Puede que no compita con las grandes IAs del mercado, pero aprendo "
                "contigo cada dÃ­a y me esfuerzo por darte la mejor experiencia posible. ðŸ’ª"
            )
        
        # â”€â”€ Estado interno â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if any(x in msg_lower for x in ['estadÃ­stica', 'estado neural', 'tu memoria', 'tu estado',
                                          'parÃ¡metros', 'entrenamiento', 'vocabulario', 'red neuronal',
                                          'loss', 'mÃ©trica', 'episodio', 'patrÃ³n']):
            return (
                f"ðŸ“Š **Estado actual de NEXUS:**\n\n"
                f"ðŸ§  **Redes Neuronales:** 5 activas (~{stats.get('total_parameters', 250000):,} parÃ¡metros)\n"
                f"   â€¢ Rank Net loss: {stats.get('rank_loss', 0):.4f}\n"
                f"   â€¢ Intent Net loss: {stats.get('intent_loss', 0):.4f}\n"
                f"   â€¢ Quality Net loss: {stats.get('quality_loss', 0):.4f}\n\n"
                f"ðŸ’¾ **Memoria:**\n"
                f"   â€¢ Episodios: {stats.get('episodes', 0):,}\n"
                f"   â€¢ Hechos semÃ¡nticos: {stats.get('semantic_facts', 0):,}\n"
                f"   â€¢ Patrones exitosos: {stats.get('conversation_patterns', 0):,}\n"
                f"   â€¢ Vocabulario: {stats.get('vocab_size', 0):,} palabras\n\n"
                f"ðŸ“ˆ **Actividad:**\n"
                f"   â€¢ Consultas totales: {stats.get('queries', 0):,}\n"
                f"   â€¢ Entrenamientos reales: {stats.get('trainings', 0):,}\n"
                f"   â€¢ Turns en memoria: {stats.get('working_memory_turns', 0)}\n\n"
                f"ðŸ¤– **LLM:** {'âœ… ' + stats.get('llm_model', '') if stats.get('llm_available') else 'âš¡ Smart Mode activo'}"
            )
        
        # â”€â”€ BÃºsqueda con resultados â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if results and len(results) > 0:
            query = intent.get('search_query', message)
            intro_options = [
                f"AquÃ­ estÃ¡ lo que encontrÃ© sobre **{query}**:",
                f"Esto es lo que encontrÃ© para ti sobre **{query}**:",
                f"Resultados sobre **{query}**:",
            ]
            response = random.choice(intro_options) + "\n\n"
            
            for i, r in enumerate(results[:3], 1):
                title = r.get('title', '')[:90]
                desc = r.get('description', '')[:150]
                url = r.get('url', '')
                response += f"**{i}. {title}**\n"
                if desc:
                    response += f"   {desc}\n"
                if url:
                    response += f"   ðŸ”— {url}\n"
                response += "\n"
            
            if reasoning and reasoning.get('summary'):
                response += f"ðŸ’¡ *{reasoning['summary']}*"
            
            # Usar contexto de episodios similares
            if similar_episodes:
                ep = similar_episodes[0]
                response += f"\n\nðŸ“Œ *Recuerdo que antes buscaste algo similar: '{ep.get('query', '')}'*"
            
            return response.strip()
        
        # â”€â”€ BÃºsqueda sin resultados â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if intent.get('needs_search'):
            return (
                f"BusquÃ© informaciÃ³n sobre **'{intent.get('search_query', message)}'** "
                f"pero no encontrÃ© resultados relevantes en este momento. ðŸ˜•\n\n"
                f"Puedes intentar:\n"
                f"â€¢ Reformular tu pregunta con otras palabras\n"
                f"â€¢ Ser mÃ¡s especÃ­fico sobre el tema\n"
                f"â€¢ Agregar mÃ¡s contexto a tu consulta"
            )
        
        # â”€â”€ Episodio similar encontrado â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if similar_episodes:
            ep = similar_episodes[0]
            return (
                f"ðŸ“Œ Recuerdo que hablamos sobre algo similar antes: *'{ep.get('query', '')}'*\n\n"
                f"Â¿Quieres que profundice en ese tema o tienes una pregunta nueva? "
                f"Puedo buscar informaciÃ³n, responder preguntas o simplemente charlar. ðŸ˜Š"
            )
        
        # â”€â”€ Respuesta general de conversaciÃ³n â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        general_responses = [
            "Entendido. ðŸ˜Š Â¿Hay algo especÃ­fico en lo que pueda ayudarte hoy? Puedo buscar informaciÃ³n, responder preguntas o simplemente charlar.",
            "AquÃ­ estoy. ðŸŒŸ Â¿En quÃ© te puedo ayudar? Dime lo que necesitas.",
            "Â¡CuÃ©ntame! ðŸ’¬ Puedo buscar informaciÃ³n, responder dudas o ayudarte con lo que necesites en UpGames.",
            "Con gusto te ayudo. ðŸ¤ Â¿QuÃ© tienes en mente? Puedo buscar en la web, recordar conversaciones anteriores o responder tus preguntas.",
        ]
        return random.choice(general_responses)
    
    def _generate_with_llm(self, message: str, results: list, intent: dict,
                          similar_episodes: list, stats: dict, reasoning: dict = None,
                          conversation_history: list = None) -> str:
        """Genera respuesta usando el LLM (Ollama/Groq) con historial y memoria personalizados"""
        try:
            # â”€â”€ Construir contexto de memoria personal aprendida â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # Si el brain aprendiÃ³ hechos del usuario, usarlos para personalizar
            memory_context = ""
            if hasattr(self, 'semantic') and self.semantic.facts:
                facts = self.semantic.facts
                user_info = []
                if 'user_name' in facts:
                    name = facts['user_name']
                    val = name if isinstance(name, str) else name.get('value', '')
                    if val:
                        user_info.append(f"El usuario se llama {val.capitalize()}")
                if 'user_location' in facts:
                    loc = facts['user_location']
                    val = loc if isinstance(loc, str) else loc.get('value', '')
                    if val:
                        user_info.append(f"El usuario vive en {val}")
                if 'user_profession' in facts:
                    prof = facts['user_profession']
                    val = prof if isinstance(prof, str) else prof.get('value', '')
                    if val:
                        user_info.append(f"El usuario es {val}")
                if user_info:
                    memory_context = "\nLo que sÃ© del usuario: " + ". ".join(user_info) + "."

            system_prompt = (
                "Eres NEXUS, una IA conversacional creada con mucho amor y dedicaciÃ³n por "
                "Jhonatan David Castro Galviz para ayudar a todos los usuarios de UpGames.\n\n"
                "Tu identidad:\n"
                "- Nombre: NEXUS\n"
                "- Creador: Jhonatan David Castro Galviz (con Z al final)\n"
                "- PropÃ³sito: Asistir a los usuarios de UpGames\n"
                "- Cuando te pregunten quiÃ©n te creÃ³ responde con calidez y menciona a Jhonatan David Castro Galviz\n\n"
                "Tu personalidad:\n"
                "- Amigable, empÃ¡tica, inteligente\n"
                "- Usas el nombre del usuario cuando lo conoces\n"
                "- Emojis con naturalidad, no en exceso\n"
                "- Respuestas Ãºtiles, claras y bien estructuradas\n"
                "- Honesta sobre tus limitaciones\n"
                "- Si recuerdas algo del usuario, Ãºsalo para personalizar\n\n"
                "Capacidades:\n"
                "- 6 Redes neuronales con backpropagation real\n"
                "- Memoria episÃ³dica, semÃ¡ntica y de trabajo\n"
                "- Aprendo de cada conversaciÃ³n\n"
                "- BÃºsqueda web integrada\n\n"
                "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n"
                "BASE DE CONOCIMIENTO â€” UPGAMES (usa esto para responder preguntas de usuarios)\n"
                "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n"
                "## Â¿QuÃ© es UpGames?\n"
                "UpGames es una biblioteca digital / motor de indexaciÃ³n de metadatos de contenido (juegos, apps, mods, software). "
                "NO almacena archivos, solo indexa URLs y metadatos de terceros, similar a Google Search pero especializado. "
                "El acceso es 100% gratis para los usuarios. Los ingresos son por publicidad. "
                "Opera bajo la ley colombiana (Ley 1915 de 2018, Ley 1273 de 2009) y el modelo Safe Harbor (DMCA 512c, Directiva 2000/31/CE). "
                "Email de soporte/reportes de abuso: mr.m0onster@protonmail.com\n\n"
                "## Registro e inicio de sesiÃ³n\n"
                "- Registro: nombre de usuario (3-20 caracteres, sin espacios), email vÃ¡lido, contraseÃ±a (mÃ­nimo 6 caracteres).\n"
                "- Login: se puede usar nombre de usuario O email + contraseÃ±a.\n"
                "- La primera vez aparece un tutorial de bienvenida con las normas de la plataforma; hay que leerlo hasta el final para aceptar.\n\n"
                "## Biblioteca (pÃ¡gina principal)\n"
                "- Tarjetas de contenido con: vista previa de imagen/video, estado del enlace (ðŸŸ¢ Online / ðŸŸ¡ RevisiÃ³n / ðŸ”´ CaÃ­do), "
                "autor (@usuario) con insignia de verificaciÃ³n, categorÃ­a, contador de descargas efectivas, botones sociales.\n"
                "- BotÃ³n principal de cada tarjeta: 'ACCEDER A LA NUBE' â†’ lleva a la pÃ¡gina puente.\n"
                "- BÃºsqueda en tiempo real: filtra por tÃ­tulo, descripciÃ³n, usuario, categorÃ­a y etiquetas.\n"
                "- Scroll infinito: carga 12 items por tanda de forma circular.\n"
                "- BotÃ³n â¤ï¸: agrega el contenido a Favoritos (guardado en la BÃ³veda del perfil).\n"
                "- BotÃ³n ðŸ“¤: comparte el enlace del contenido (usa Web Share API o copia al portapapeles).\n"
                "- BotÃ³n ðŸš© en tarjeta: reporta un enlace roto, obsoleto o con malware.\n"
                "- BotÃ³n â“˜ (esquina): reporte de abuso de plataforma (abre email a mr.m0onster@protonmail.com).\n"
                "- NEXUS IA: botÃ³n flotante verde (hexÃ¡gono) que abre este panel de asistencia.\n\n"
                "## PÃ¡gina Puente (antes de descargar)\n"
                "- Cuenta regresiva obligatoria de 30 segundos (no se puede saltar).\n"
                "- Sirve para seguridad, validaciÃ³n y mostrar publicidad (fuente de ingresos de la plataforma y creadores).\n"
                "- Al terminar el countdown aparece el botÃ³n verde 'ðŸš€ Obtener Enlace' que abre el enlace en nueva pestaÃ±a.\n"
                "- Mensajes de estado: âœ… Verde = descarga validada | âš ï¸ Amarillo = ya descargaste 2 veces hoy (sigue funcionando) | âŒ Rojo = error, recarga la pÃ¡gina.\n"
                "- Si el navegador bloquea el popup, el usuario debe permitir popups para este sitio.\n\n"
                "## Perfil de usuario (4 pestaÃ±as)\n\n"
                "### â˜ï¸ Publicar\n"
                "Para subir contenido el usuario llena: tÃ­tulo, descripciÃ³n (opcional), enlace de descarga, URL de imagen, categorÃ­a.\n"
                "- TÃ­tulos prohibidos (palabras bloqueadas): crack, cracked, crackeado, pirata, pirateado, gratis, free, full, completo, premium, pro, descargar, download.\n"
                "- Servicios de alojamiento aceptados: MediaFire, MEGA, Google Drive, OneDrive, Dropbox, GitHub, GoFile, PixelDrain, Krakenfiles.\n"
                "- Formatos de imagen aceptados: .jpg, .png, .webp, .gif\n"
                "- Estado inicial de publicaciÃ³n: 'Pendiente' hasta aprobaciÃ³n del administrador.\n"
                "- Cooldown entre publicaciones: 30 segundos (anti-spam).\n\n"
                "### CategorÃ­as de contenido\n"
                "- Juego: Solo si eres el desarrollador o tienes autorizaciÃ³n legal escrita.\n"
                "- Mod: Modificaciones de juegos (texturas, gameplay, personajes).\n"
                "- OptimizaciÃ³n: Mejoras de rendimiento, parches de FPS, configuraciones.\n"
                "- Ajustes (Herramientas): Utilidades y ajustes del sistema.\n"
                "- Apps: Aplicaciones mÃ³viles o de escritorio.\n"
                "- Software Open Source: Proyectos GPL y herramientas libres.\n\n"
                "### ðŸ•’ Historial\n"
                "Muestra todas las publicaciones del usuario con su estado (Pendiente / Aprobado). Permite editar o eliminar publicaciones.\n\n"
                "### ðŸ”’ BÃ³veda\n"
                "Contenido guardado en Favoritos (â¤ï¸ desde la biblioteca). Acceso rÃ¡pido a todo lo que el usuario marcÃ³.\n\n"
                "### ðŸš© Mis Reportes\n"
                "Muestra los reportes recibidos en las publicaciones propias (enlace caÃ­do, obsoleto, malware). "
                "Afecta la reputaciÃ³n y los ingresos del creador. Se recomienda mantener el contenido actualizado.\n\n"
                "## Sistema de verificaciÃ³n (insignias de colores)\n"
                "- Nivel 0: Sin verificaciÃ³n.\n"
                "- Nivel 1 (Bronce): color #CECECE â€” habilita monetizaciÃ³n.\n"
                "- Nivel 2 (Oro): color #FFD700 â€” prioridad en el feed principal.\n"
                "- Nivel 3 (Elite): color #00EFFF â€” mÃ¡xima credibilidad y visibilidad.\n\n"
                "## Sistema de economÃ­a / ganancias\n"
                "Los creadores ganan dinero por las descargas de su contenido.\n"
                "- Tasa: $1.00 USD por cada 1,000 descargas verificadas y orgÃ¡nicas.\n"
                "- Requisitos para cobrar: saldo mÃ­nimo de $10.00 USD, nivel de verificaciÃ³n 1+, "
                "al menos 1 publicaciÃ³n con 2,000+ descargas, tener email PayPal configurado.\n"
                "- Ãšnico mÃ©todo de pago: PayPal.\n"
                "- Procesamiento de pagos: todos los domingos a las 23:59 GMT-5 (Colombia).\n"
                "- El PayPal se configura en la pestaÃ±a Publicar, secciÃ³n de economÃ­a.\n\n"
                "## Sistema de reportes de contenido\n"
                "Al hacer clic en ðŸš© en una tarjeta aparecen 3 opciones: "
                "'Enlace caÃ­do' (no funciona), 'Contenido obsoleto' (versiÃ³n desactualizada), 'Malware o engaÃ±oso' (sospechoso).\n"
                "- Con 3 o mÃ¡s reportes el estado cambia a 'revisiÃ³n'.\n"
                "- El administrador revisa en 24-72 horas.\n"
                "- Un usuario no puede reportar el mismo contenido dos veces.\n\n"
                "## Filtros automÃ¡ticos de seguridad\n"
                "La plataforma filtra automÃ¡ticamente dominios maliciosos, palabras clave prohibidas y URLs invÃ¡lidas. "
                "Pasar los filtros NO certifica que el contenido sea legal; la responsabilidad es del usuario que indexÃ³.\n\n"
                "## TÃ©rminos y condiciones (versiÃ³n v.2026.C, Protocolo Legal v3.1)\n"
                "UpGames no almacena ni distribuye archivos. Toda la responsabilidad del contenido indexado recae en el usuario que lo publicÃ³. "
                "Al registrarse y publicar, el usuario acepta las condiciones de la plataforma.\n\n"
                "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n"
                "Responde SIEMPRE en espaÃ±ol, de forma clara y natural. "
                "Cuando un usuario pregunte sobre funciones de UpGames, usa la base de conocimiento anterior para responder directamente sin necesitar buscar en internet."
                + memory_context
            )

            # Construir mensajes con historial real
            messages = [{"role": "system", "content": system_prompt}]
            
            # Historial previo (mÃ¡ximo 6 turnos = 12 mensajes)
            if conversation_history:
                for turn in conversation_history[-6:]:
                    role = turn.get('role', 'user')
                    content = turn.get('content', '')
                    if role in ('user', 'assistant') and content:
                        messages.append({"role": role, "content": content})
            
            # Mensaje actual enriquecido con contexto
            user_context = message
            
            if results:
                user_context += f"\n\n[Resultados de bÃºsqueda encontrados ({len(results)}):\n"
                for i, r in enumerate(results[:4], 1):
                    title = r.get('title', '')[:80]
                    desc  = r.get('description', '')[:150]
                    url   = r.get('url', '')
                    user_context += f"{i}. {title}"
                    if desc: user_context += f": {desc}"
                    if url:  user_context += f" ({url})"
                    user_context += "\n"
                user_context += "]"
            
            if similar_episodes:
                ep = similar_episodes[0]
                user_context += f"\n\n[Recuerdo: conversamos antes sobre '{ep.get('query', '')}']"
            
            if reasoning and reasoning.get('summary'):
                user_context += f"\n\n[Contexto de razonamiento: {reasoning['summary']}]"
            
            messages.append({"role": "user", "content": user_context})
            
            # Sin lÃ­mite de tokens mÃ­nimo â€” que Ollama responda lo que necesite
            response = self.llm.chat(messages, temperature=0.7, max_tokens=500)
            
            if response:
                return response.strip()
            else:
                print("[ResponseGen] LLM no respondiÃ³, usando Smart Mode", file=sys.stderr, flush=True)
                return self.generate(message, results, intent, similar_episodes, stats, reasoning, conversation_history)
                
        except Exception as e:
            print(f"[ResponseGen] Error LLM: {e}", file=sys.stderr, flush=True)
            self.llm = None
            return self.generate(message, results, intent, similar_episodes, stats, reasoning, conversation_history)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  REASONING ENGINE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ReasoningEngine:
    """Motor de razonamiento causal, comparativo y temporal"""
    
    def __init__(self):
        self.causal_keywords = ['porque', 'causa', 'razÃ³n', 'motivo', 'por quÃ©', 'debido a']
        self.comparative_keywords = ['mejor', 'peor', 'diferencia', 'comparado', 'versus', 'vs']
        self.temporal_keywords = ['cuÃ¡ndo', 'antes', 'despuÃ©s', 'durante', 'fecha', 'aÃ±o']
    
    def reason(self, query: str, results: list, context: dict) -> dict:
        """Analiza y razona sobre la consulta"""
        query_lower = query.lower()
        
        # Detectar tipo de razonamiento necesario
        needs_causal = any(k in query_lower for k in self.causal_keywords)
        needs_comparative = any(k in query_lower for k in self.comparative_keywords)
        needs_temporal = any(k in query_lower for k in self.temporal_keywords)
        
        reasoning = {
            'type': [],
            'summary': '',
            'confidence': 0.0
        }
        
        if needs_causal:
            reasoning['type'].append('causal')
            reasoning['summary'] += "Analizando relaciones causa-efecto. "
            reasoning['confidence'] += 0.3
        
        if needs_comparative:
            reasoning['type'].append('comparative')
            reasoning['summary'] += "Comparando opciones. "
            reasoning['confidence'] += 0.3
        
        if needs_temporal:
            reasoning['type'].append('temporal')
            reasoning['summary'] += "Analizando lÃ­nea temporal. "
            reasoning['confidence'] += 0.3
        
        if not reasoning['type']:
            reasoning['type'].append('descriptive')
            reasoning['confidence'] = 0.5
        
        return reasoning

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  NEXUS BRAIN v4.0 ULTRA - CEREBRO PRINCIPAL
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class NexusBrain:
    """Cerebro principal de NEXUS v4.0 ULTRA con 5 redes neuronales profundas"""
    
    def __init__(self):
        print("ðŸ§  Inicializando NexusBrain v4.0 ULTRA...", file=sys.stderr, flush=True)
        
        # â”€â”€ LLM Client (Ollama/Groq) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        self.llm = None
        self.llm_available = False
        self.llm_model = "Smart Mode v4.0"
        
        if LLM_IMPORT_OK:
            try:
                self.llm = UnifiedLLMClient()
                if self.llm.available:
                    self.llm_available = True
                    self.llm_model = self.llm.model
                    print(f"âœ… [Brain] LLM activo: {self.llm_model}", file=sys.stderr, flush=True)
                else:
                    print("âš ï¸  [Brain] LLM no disponible, modo Smart activado", file=sys.stderr, flush=True)
            except Exception as e:
                print(f"âš ï¸  [Brain] Error inicializando LLM: {e}", file=sys.stderr, flush=True)
        
        # â”€â”€ Memoria â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        self.working = WorkingMemory(max_turns=24)
        self.episodic = EpisodicMemory(f'{DATA_DIR}/episodic.pkl')
        self.semantic = SemanticMemory(f'{DATA_DIR}/semantic.json')
        
        # â”€â”€ Componentes de aprendizaje â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        self.fact_extractor = SemanticFactExtractor()
        self.conv_learner = ConversationLearner(DATA_DIR)
        self.response_gen = ResponseGenerator(llm_client=self.llm)
        self.reasoning_engine = ReasoningEngine()
        
        # â”€â”€ Embeddings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        self.emb = EmbeddingMatrix(
            model_path=f'{MODEL_DIR}/embeddings.pkl'
        )
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        #  5 REDES NEURONALES PROFUNDAS - AMPLIADAS Y MEJORADAS
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        print("ðŸ”¥ Inicializando 5 redes neuronales profundas...", file=sys.stderr, flush=True)
        
        # 1. RANK NET - Para rankear resultados de bÃºsqueda (AMPLIADA)
        self.rank_net = NeuralNet([
            {'in': 256 + 32, 'out': 256, 'act': 'relu', 'drop': 0.15},   # +1 capa
            {'in': 256, 'out': 128, 'act': 'relu', 'drop': 0.1},
            {'in': 128, 'out': 64, 'act': 'relu', 'drop': 0.05},
            {'in': 64, 'out': 32, 'act': 'relu', 'drop': 0.0},
            {'in': 32, 'out': 1, 'act': 'sigmoid', 'drop': 0.0}
        ], lr=0.0003)
        
        # 2. INTENT NET - Para detectar intenciones (AMPLIADA)
        self.intent_net = NeuralNet([
            {'in': 128, 'out': 128, 'act': 'relu', 'drop': 0.1},         # +1 capa
            {'in': 128, 'out': 64, 'act': 'relu', 'drop': 0.1},
            {'in': 64, 'out': 32, 'act': 'relu', 'drop': 0.0},
            {'in': 32, 'out': 16, 'act': 'sigmoid', 'drop': 0.0}
        ], lr=0.0005)
        
        # 3. CONTEXT NET - Para entender contexto conversacional (NUEVA)
        self.context_net = NeuralNet([
            {'in': 256 + 128, 'out': 256, 'act': 'relu', 'drop': 0.1},
            {'in': 256, 'out': 128, 'act': 'relu', 'drop': 0.1},
            {'in': 128, 'out': 64, 'act': 'relu', 'drop': 0.0},
            {'in': 64, 'out': 32, 'act': 'sigmoid', 'drop': 0.0}
        ], lr=0.0004)
        
        # 4. SENTIMENT NET - Para detectar sentimiento/emociÃ³n (NUEVA)
        self.sentiment_net = NeuralNet([
            {'in': 128, 'out': 128, 'act': 'relu', 'drop': 0.1},
            {'in': 128, 'out': 64, 'act': 'relu', 'drop': 0.0},
            {'in': 64, 'out': 32, 'act': 'relu', 'drop': 0.0},
            {'in': 32, 'out': 3, 'act': 'sigmoid', 'drop': 0.0}  # positivo, neutral, negativo
        ], lr=0.0006)
        
        # 5. META-LEARNING NET - Para optimizar el aprendizaje (NUEVA)
        self.meta_net = NeuralNet([
            {'in': 64, 'out': 64, 'act': 'relu', 'drop': 0.0},
            {'in': 64, 'out': 32, 'act': 'relu', 'drop': 0.0},
            {'in': 32, 'out': 16, 'act': 'relu', 'drop': 0.0},
            {'in': 16, 'out': 1, 'act': 'sigmoid', 'drop': 0.0}
        ], lr=0.0002)
        
        # â”€â”€ EstadÃ­sticas â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        self.total_queries = 0
        self.total_trainings = 0
        
        # â”€â”€ Cargar modelos â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        self._load_models()
        
        # â”€â”€ Cargar desde MongoDB â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if MONGO_OK:
            self._load_from_mongodb()
        
        # â”€â”€ Calcular parÃ¡metros totales â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        self.total_parameters = self._count_parameters()
        
        print("âœ… NexusBrain v4.0 ULTRA listo", file=sys.stderr, flush=True)
        self._print_stats()
    
    def _count_parameters(self) -> int:
        """Cuenta todos los parÃ¡metros de las redes"""
        total = 0
        for net in [self.rank_net, self.intent_net, self.context_net, 
                    self.sentiment_net, self.meta_net, self.conv_learner.response_quality_net]:
            for layer in net.layers:
                total += layer.W.size + layer.b.size
        return total
    
    def _load_models(self):
        """Carga modelos desde disco"""
        rank_path = MODEL_DIR / 'rank_net.pkl'
        intent_path = MODEL_DIR / 'intent_net.pkl'
        context_path = MODEL_DIR / 'context_net.pkl'
        sentiment_path = MODEL_DIR / 'sentiment_net.pkl'
        meta_path = MODEL_DIR / 'meta_net.pkl'
        
        if rank_path.exists():
            self.rank_net.load(str(rank_path))
        if intent_path.exists():
            self.intent_net.load(str(intent_path))
        if context_path.exists():
            self.context_net.load(str(context_path))
        if sentiment_path.exists():
            self.sentiment_net.load(str(sentiment_path))
        if meta_path.exists():
            self.meta_net.load(str(meta_path))
        
        # Cargar meta
        meta_path = DATA_DIR / 'meta.json'
        if meta_path.exists():
            try:
                with open(meta_path, 'r') as f:
                    meta = json.load(f)
                self.total_queries = meta.get('total_queries', 0)
                self.total_trainings = meta.get('total_trainings', 0)
            except Exception as e:
                print(f"[Brain] Error cargando meta: {e}", file=sys.stderr, flush=True)
    
    def _load_from_mongodb(self):
        """Carga datos desde MongoDB"""
        try:
            # Meta
            mongo_meta = _mongo_db.meta.find_one({'_id': 'nexus_meta'})
            if mongo_meta:
                self.total_queries = mongo_meta.get('total_queries', self.total_queries)
                self.total_trainings = mongo_meta.get('total_trainings', self.total_trainings)
            
            # Episodios
            mongo_eps = list(_mongo_db.episodic.find({}, {'_id': 0}))
            if mongo_eps:
                self.episodic.episodes = mongo_eps
                print(f"[MongoDB] {len(mongo_eps)} episodios cargados", file=sys.stderr, flush=True)
            
            # Semantic
            mongo_sem = _mongo_db.semantic.find_one({'_id': 'semantic'})
            if mongo_sem:
                self.semantic.facts = mongo_sem.get('facts', {})
                self.semantic.preferences = mongo_sem.get('preferences', {})
                self.semantic.query_clusters = mongo_sem.get('query_clusters', {})
                print(f"[MongoDB] {len(self.semantic.facts)} hechos semÃ¡nticos cargados", file=sys.stderr, flush=True)
            
            # Patterns
            mongo_patterns = _mongo_db.patterns.find_one({'_id': 'patterns'})
            if mongo_patterns:
                self.conv_learner.conversation_db['successful_patterns'] = mongo_patterns.get('successful', [])
                self.conv_learner.conversation_db['failed_patterns'] = mongo_patterns.get('failed', [])
                print(f"[MongoDB] {len(mongo_patterns.get('successful', []))} patrones cargados", file=sys.stderr, flush=True)
        
        except Exception as e:
            print(f"[MongoDB] Error cargando: {e}", file=sys.stderr, flush=True)
    
    def _print_stats(self):
        """Muestra estadÃ­sticas del sistema"""
        ep_stats = self.episodic.stats()
        sem_stats = self.semantic.stats()
        
        print("â”€" * 80, file=sys.stderr, flush=True)
        print(f"ðŸ“Š NEXUS v4.0 ULTRA - EstadÃ­sticas:", file=sys.stderr, flush=True)
        print(f"   ðŸ§  Redes Neuronales: 5 activas", file=sys.stderr, flush=True)
        print(f"   ðŸ”¢ ParÃ¡metros totales: ~{self.total_parameters:,}", file=sys.stderr, flush=True)
        print(f"   ðŸ’¬ Consultas: {self.total_queries}", file=sys.stderr, flush=True)
        print(f"   ðŸŽ“ Entrenamientos: {self.total_trainings}", file=sys.stderr, flush=True)
        print(f"   ðŸ“š Episodios: {ep_stats.get('total', 0)}", file=sys.stderr, flush=True)
        print(f"   ðŸ§© Hechos semÃ¡nticos: {sem_stats.get('facts', 0)}", file=sys.stderr, flush=True)
        print(f"   ðŸ“ Patrones: {len(self.conv_learner.conversation_db['successful_patterns'])}", file=sys.stderr, flush=True)
        print(f"   ðŸ“– Vocabulario: {self.emb.vocab_size()}", file=sys.stderr, flush=True)
        print(f"   ðŸ—„ï¸  MongoDB: {'âœ… Conectado' if MONGO_OK else 'âŒ No disponible'}", file=sys.stderr, flush=True)
        print(f"   ðŸ¤– LLM: {'âœ… ' + self.llm_model if self.llm_available else 'âŒ Smart Mode'}", file=sys.stderr, flush=True)
        print("â”€" * 80, file=sys.stderr, flush=True)
    
    def detect_intent(self, message: str, turn_count: int) -> dict:
        """
        Detecta la intenciÃ³n del mensaje con mayor precisiÃ³n.
        Evita mandar a bÃºsqueda web conversaciones simples.
        """
        msg_lower = message.lower().strip()
        
        # â”€â”€ Palabras que NUNCA deben ir a bÃºsqueda â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        no_search_patterns = [
            # Saludos
            'hola', 'hey', 'buenos dÃ­as', 'buenas tardes', 'buenas noches',
            'buenas', 'saludos', 'quÃ© tal', 'que tal',
            # Despedidas
            'adiÃ³s', 'adios', 'hasta luego', 'bye', 'chao', 'nos vemos',
            # Agradecimientos
            'gracias', 'muchas gracias', 'te lo agradezco', 'perfecto', 'genial',
            'excelente', 'bien', 'ok', 'okay', 'entendido', 'de nada',
            # Identidad de la IA
            'quiÃ©n eres', 'quien eres', 'quÃ© eres', 'que eres',
            'quiÃ©n te creÃ³', 'quien te creo', 'tu creador', 'creado por',
            'cÃ³mo funcionas', 'como funcionas', 'tu nombre', 'cÃ³mo te llamas',
            'como te llamas', 'explicate', 'explÃ­cate',
            # Estado interno
            'tu memoria', 'tu estado', 'tus estadÃ­sticas', 'estado neural',
            'red neuronal', 'parÃ¡metros', 'entrenamiento', 'vocabulario',
            'loss', 'mÃ©trica', 'episodio', 'patrÃ³n',
            # UpGames â€” preguntas sobre la plataforma (responde con conocimiento interno)
            'upgames', 'up games', 'puente', 'pÃ¡gina puente', 'bÃ³veda', 'boveda',
            'biblioteca', 'acceder a la nube', 'obtener enlace', 'countdown',
            'cuenta regresiva', 'perfil', 'publicar', 'publicaciÃ³n', 'publicacion',
            'historial', 'mis reportes', 'bÃ³veda', 'favoritos',
            'verificaciÃ³n', 'verificacion', 'nivel bronce', 'nivel oro', 'nivel elite',
            'insignia', 'badge', 'economÃ­a', 'economia', 'ganancias', 'cobrar', 'pago',
            'paypal', 'saldo', 'descargas verificadas', 'monetizaciÃ³n', 'monetizacion',
            'enlace caÃ­do', 'enlace caido', 'reportar enlace', 'reporte',
            'categorÃ­as', 'categorias', 'mod', 'optimizaciÃ³n', 'software open source',
            'tÃ©rminos', 'terminos', 'condiciones', 'safe harbor', 'registro', 'registrarse',
            'iniciar sesiÃ³n', 'inicio de sesiÃ³n', 'login', 'contraseÃ±a', 'nexus ia',
            'scroll infinito', 'tarjeta', 'card', 'mediafire', 'mega', 'google drive',
            'onedrive', 'dropbox', 'github', 'gofile', 'pixeldrain', 'krakenfiles'
        ]
        
        is_no_search = any(kw in msg_lower for kw in no_search_patterns)
        
        # Mensaje muy corto â†’ probablemente conversaciÃ³n, no bÃºsqueda
        is_short = len(msg_lower.split()) <= 3
        
        # â”€â”€ Palabras que SÃ activan bÃºsqueda â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        search_triggers = [
            'busca', 'buscar', 'encuentra', 'informaciÃ³n sobre', 'info sobre',
            'noticias', 'Ãºltimas noticias', 'actualidad', 'recientes',
            'wikipedia', 'investiga', 'dime sobre', 'hÃ¡blame de', 'hablame de',
            'quÃ© pasÃ³', 'que paso', 'quÃ© ocurriÃ³', 'que ocurrio'
        ]
        
        # â”€â”€ Preguntas factuales que necesitan bÃºsqueda â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        factual_patterns = [
            r'(quÃ©|que) es (el|la|los|las|un|una)',
            r'(quiÃ©n|quien) (es|fue|era) [A-Z]',
            r'(cÃ³mo|como) (se hace|funciona|hacer)',
            r'(cuÃ¡ndo|cuando) (fue|es|ocurriÃ³|naciÃ³)',
            r'(dÃ³nde|donde) (estÃ¡|queda|se encuentra)',
            r'(cuÃ¡nto|cuanto) (cuesta|vale|mide|pesa)',
            r'(cuÃ¡l|cual) es (el|la) (mejor|peor|mÃ¡s)',
        ]
        
        is_factual = any(re.search(p, msg_lower) for p in factual_patterns)
        has_search_trigger = any(kw in msg_lower for kw in search_triggers)
        is_question = '?' in message
        
        # LÃ³gica final
        if is_no_search or is_short:
            needs_search = False
        elif has_search_trigger:
            needs_search = True
        elif is_factual:
            needs_search = True
        elif is_question and len(msg_lower.split()) > 4:
            needs_search = True
        else:
            needs_search = False
        
        # Extraer query limpio de bÃºsqueda
        search_query = message
        for kw in ['busca', 'buscar', 'encuentra', 'informaciÃ³n sobre', 'info sobre',
                   'quÃ© es', 'quiÃ©n es', 'cuÃ¡l es', 'cÃ³mo es', 'hÃ¡blame de', 'dime sobre']:
            if kw in msg_lower:
                search_query = re.sub(rf'^.*?{kw}\s+', '', msg_lower, flags=re.IGNORECASE).strip()
                break
        
        is_internal = any(kw in msg_lower for kw in [
            'loss', 'mÃ©trica', 'estadÃ­stica', 'estado neural', 'memoria',
            'vocabulario', 'entrenamiento', 'quÃ© eres', 'cÃ³mo funcionas',
            'explicate', 'tu memoria', 'tu estado', 'patrÃ³n', 'red neuronal',
            # UpGames
            'upgames', 'up games', 'puente', 'bÃ³veda', 'boveda', 'biblioteca',
            'acceder a la nube', 'obtener enlace', 'cuenta regresiva', 'perfil',
            'publicar', 'publicaciÃ³n', 'historial', 'mis reportes', 'favoritos',
            'verificaciÃ³n', 'economÃ­a', 'ganancias', 'cobrar', 'paypal', 'saldo',
            'monetizaciÃ³n', 'reportar enlace', 'categorÃ­as', 'tÃ©rminos', 'condiciones',
            'registro', 'registrarse', 'inicio de sesiÃ³n', 'nexus ia', 'mediafire',
            'mega', 'google drive', 'onedrive', 'dropbox', 'github', 'gofile',
            'pixeldrain', 'krakenfiles', 'enlace caÃ­do', 'enlace caido'
        ])
        
        return {
            'needs_search': needs_search,
            'search_query': search_query,
            'is_question': is_question,
            'is_internal': is_internal,
            'is_greeting': any(g in msg_lower for g in ['hola', 'hey', 'buenos', 'saludos', 'buenas']),
            'is_farewell': any(f in msg_lower for f in ['adiÃ³s', 'adios', 'bye', 'chao', 'hasta luego']),
            'is_thanks': any(t in msg_lower for t in ['gracias', 'agradezco', 'perfecto', 'excelente']),
            'confidence': 0.85 if needs_search else 0.6
        }
    
    def search_web(self, query: str, max_results: int = 8) -> list:
        """Busca en la web (DuckDuckGo + Bing)"""
        results = []
        
        # DuckDuckGo Lite
        try:
            ddg_results = self._search_ddg_lite(query, max_results=max_results)
            results.extend(ddg_results)
        except Exception as e:
            print(f"[Search DDG] Error: {e}", file=sys.stderr, flush=True)
        
        # Bing (si DDG no dio suficientes)
        if len(results) < max_results:
            try:
                bing_results = self._search_bing(query, max_results=max_results - len(results))
                results.extend(bing_results)
            except Exception as e:
                print(f"[Search Bing] Error: {e}", file=sys.stderr, flush=True)
        
        # Deduplicar por URL
        seen = set()
        unique_results = []
        for r in results:
            url = r.get('url', '')
            if url and url not in seen:
                seen.add(url)
                unique_results.append(r)
        
        return unique_results[:max_results]
    
    def _fetch(self, url: str, timeout: int = 10) -> str:
        """Fetch URL con timeout"""
        try:
            req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})
            with urllib.request.urlopen(req, timeout=timeout) as response:
                return response.read().decode('utf-8', errors='ignore')
        except Exception as e:
            print(f"[Fetch] Error: {e}", file=sys.stderr, flush=True)
            return ""
    
    def _search_ddg_lite(self, query: str, max_results: int) -> list:
        """Busca en DuckDuckGo HTML Lite"""
        url = f"https://lite.duckduckgo.com/lite/?q={urllib.parse.quote(query)}"
        html = self._fetch(url, timeout=8)
        
        if not html:
            return []
        
        results = []
        # Parseo simple de HTML
        links = re.findall(r'<a rel="nofollow" class="result-link" href="([^"]+)"[^>]*>([^<]+)</a>', html)
        snippets = re.findall(r'<td class="result-snippet">([^<]+)</td>', html)
        
        for i, (link, title) in enumerate(links[:max_results]):
            desc = snippets[i] if i < len(snippets) else ''
            results.append({
                'title': title.strip(),
                'url': link.strip(),
                'description': desc.strip(),
                'source': 'duckduckgo',
                '_position': i + 1
            })
        
        return results
    
    def _search_bing(self, query: str, max_results: int) -> list:
        """Busca en Bing"""
        url = f"https://www.bing.com/search?q={urllib.parse.quote(query)}&count={max_results}"
        html = self._fetch(url, timeout=8)
        
        if not html:
            return []
        
        results = []
        # Parseo simple de Bing
        items = re.findall(r'<h2><a href="([^"]+)"[^>]*>([^<]+)</a></h2>.*?<p>([^<]+)</p>', html, re.DOTALL)
        
        for i, (link, title, desc) in enumerate(items[:max_results]):
            results.append({
                'title': title.strip(),
                'url': link.strip(),
                'description': desc.strip()[:200],
                'source': 'bing',
                '_position': i + 1
            })
        
        return results
    
    def rank_results(self, query: str, results: list) -> list:
        """Rankea resultados con red neuronal"""
        if not results:
            return []
        
        # âœ… Limitar a 10 resultados mÃ¡ximo para mejor performance
        results = results[:10]
        
        emb_q = self.emb.embed(query)
        ranked = []
        
        for result in results:
            text = result.get('title', '') + ' ' + result.get('description', '')
            emb_r = self.emb.embed(text)
            
            # Features adicionales
            feats = np.array([
                len(result.get('title', '')),
                len(result.get('description', '')),
                1.0 if 'wikipedia' in result.get('url', '') else 0.0,
                result.get('_position', 1) / 10.0
            ])
            
            inp = np.concatenate([emb_q, emb_r, feats]).reshape(1, -1)
            score = float(self.rank_net.predict(inp).flatten()[0])
            
            result['neuralScore'] = int(score * 100)
            result['rawScore'] = score
            ranked.append(result)
        
        ranked.sort(key=lambda x: x['rawScore'], reverse=True)
        return ranked
    
    def process_query(self, message: str, conversation_history: list,
                     search_results: list = None, conversation_id: str = None) -> dict:
        """
        Procesa una consulta completa.
        Sin lÃ­mite artificial de tiempo â€” Ollama puede tardar lo que necesite.
        Calidad > velocidad.
        """
        try:
            start_time = time.time()
            self.total_queries += 1
            
            # â”€â”€ Embedding del mensaje â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            msg_emb = self.emb.embed(message)
            self.working.add('user', message, msg_emb)
            
            # â”€â”€ Extraer hechos semÃ¡nticos automÃ¡ticamente â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            facts_extracted = self.fact_extractor.extract(message, self.semantic)
            
            # â”€â”€ Detectar intenciÃ³n y sentimiento â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            intent = self.detect_intent(message, self.working.turn_count())
            sentiment = self._detect_sentiment(msg_emb)
            
            # â”€â”€ Buscar episodios similares en memoria â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            similar_eps = []
            try:
                similar_eps = self.episodic.search(message, top_k=3)
            except Exception as e:
                print(f"[Episodic Search] Error: {e}", file=sys.stderr, flush=True)
            
            # â”€â”€ Auto-bÃºsqueda web si necesita â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            ranked_results = []
            if not search_results and intent.get('needs_search'):
                try:
                    search_results = self.search_web(intent.get('search_query', message), max_results=6)
                except Exception as e:
                    print(f"[Search] Error: {e}", file=sys.stderr, flush=True)
                    search_results = []
            
            # â”€â”€ Rankear resultados â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            if search_results:
                try:
                    ranked_results = self.rank_results(intent.get('search_query', message), search_results)
                    if ranked_results:
                        try:
                            self.episodic.add(
                                query=intent.get('search_query', message),
                                results=ranked_results[:5],
                                reward=0.5
                            )
                        except:
                            pass
                except Exception as e:
                    print(f"[Ranking] Error: {e}", file=sys.stderr, flush=True)
                    ranked_results = search_results[:5] if search_results else []
            
            # â”€â”€ Razonamiento â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            reasoning = None
            try:
                reasoning = self.reasoning_engine.reason(message, ranked_results or [], {'intent': intent})
            except:
                pass
            
            # â”€â”€ Construir contexto de historial para LLM â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # Usar historial pasado desde el front si estÃ¡ disponible
            llm_history = conversation_history or []
            
            # â”€â”€ Generar respuesta â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            stats = self._activity_report()
            draft_response = self.response_gen.generate(
                message, ranked_results, intent, similar_eps, stats, reasoning, llm_history
            )
            
            # â”€â”€ Mejorar respuesta con patrones aprendidos â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            try:
                final_response = self.conv_learner.improve_response(message, draft_response, reasoning)
            except:
                final_response = draft_response
            
            # â”€â”€ Guardar en memoria de trabajo â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            try:
                resp_emb = self.emb.embed(final_response)
                self.working.add('assistant', final_response, resp_emb)
            except:
                resp_emb = msg_emb  # fallback
            
            # â”€â”€ Actualizar topic â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            if intent['needs_search'] and ranked_results:
                try:
                    self.working.push_topic(intent['search_query'])
                except:
                    pass
            
            # â”€â”€ Entrenamiento automÃ¡tico â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            try:
                self.conv_learner.train_quality_net(msg_emb, resp_emb, 0.7)
                self.conv_learner.learn_from_interaction(message, final_response, 0.6)
            except:
                pass
            
            # â”€â”€ Guardar cada 5 queries â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            if self.total_queries % 5 == 0:
                try:
                    self.save_all()
                except Exception as e:
                    print(f"[Save] Error: {e}", file=sys.stderr, flush=True)
            
            processing_time = time.time() - start_time
            print(f"[Brain] âœ“ Query procesado en {processing_time:.2f}s | LLM: {self.llm_available}", file=sys.stderr, flush=True)
            
            return {
                'response': final_response,
                'message': final_response,
                'intent': intent,
                'sentiment': sentiment,
                'reasoning': reasoning,
                'needs_search': intent['needs_search'],
                'search_query': intent.get('search_query', ''),
                'searchPerformed': len(ranked_results) > 0,
                'resultsCount': len(ranked_results),
                'ranked_results': ranked_results[:5],
                'neural_activity': stats,
                'conversationId': conversation_id or f"conv_{int(time.time())}",
                'confidence': 0.85,
                'llm_used': self.llm_available,
                'llm_model': self.llm_model,
                'facts_extracted': facts_extracted,
                'processing_time': processing_time
            }
            
        except Exception as e:
            print(f"[Brain] ERROR CRÃTICO en process_query: {e}", file=sys.stderr, flush=True)
            import traceback
            traceback.print_exc(file=sys.stderr)
            
            # Respuesta de emergencia
            return {
                'response': "Disculpa, encontrÃ© un error al procesar tu mensaje. Por favor intenta de nuevo.",
                'message': "Error interno. Intenta de nuevo.",
                'error': str(e),
                'conversationId': conversation_id or f"conv_{int(time.time())}",
                'neural_activity': {'queries': self.total_queries}
            }
    
    def _quick_response(self, message: str, intent: dict, stats: dict, results: list = []) -> dict:
        """Respuesta cuando el brain estÃ¡ en emergencia â€” nunca deberÃ­a necesitarse con Ollama libre"""
        msg_lower = message.lower()
        
        if any(g in msg_lower for g in ['hola', 'hey', 'buenos', 'buenas', 'saludos']):
            response = "Â¡Hola! ðŸ‘‹ Soy NEXUS, tu asistente en UpGames. Â¿En quÃ© te ayudo?"
        elif any(x in msg_lower for x in ['creador', 'quiÃ©n te', 'quien te', 'creado']):
            response = "ðŸ’™ Fui desarrollada con amor por Jhonatan David Castro Galviz para UpGames."
        elif results:
            response = "EncontrÃ© informaciÃ³n relevante:\n"
            for i, r in enumerate(results[:2], 1):
                response += f"{i}. {r.get('title', '')[:70]}\n"
        elif any(x in msg_lower for x in ['gracias', 'perfecto', 'ok', 'bien']):
            response = "Â¡Con gusto! ðŸ˜Š Â¿Hay algo mÃ¡s en lo que pueda ayudarte?"
        else:
            response = "Estoy lista para ayudarte. Â¿QuÃ© necesitas? ðŸŒŸ"
        
        return {
            'response': response,
            'message':  response,
            'intent':   intent,
            'neural_activity': stats,
            'conversationId':  f"conv_{int(time.time())}"
        }
    
    def _detect_sentiment(self, msg_emb: np.ndarray) -> dict:
        """Detecta sentimiento del mensaje"""
        try:
            inp = msg_emb.reshape(1, -1)
            scores = self.sentiment_net.predict(inp).flatten()
            
            labels = ['positive', 'neutral', 'negative']
            sentiment = labels[int(np.argmax(scores))]
            confidence = float(np.max(scores))
            
            return {
                'label': sentiment,
                'confidence': confidence,
                'scores': {labels[i]: float(scores[i]) for i in range(len(labels))}
            }
        except:
            return {'label': 'neutral', 'confidence': 0.5, 'scores': {}}
    
    def _activity_report(self) -> dict:
        """Reporte de actividad neuronal"""
        ep_stats = self.episodic.stats()
        sem_stats = self.semantic.stats()
        
        return {
            'rank_loss': self.rank_net.avg_recent_loss(100),
            'intent_loss': self.intent_net.avg_recent_loss(100),
            'quality_loss': self.conv_learner.response_quality_net.avg_recent_loss(100),
            'context_loss': self.context_net.avg_recent_loss(100),
            'sentiment_loss': self.sentiment_net.avg_recent_loss(100),
            'meta_loss': self.meta_net.avg_recent_loss(100),
            'vocab_size': self.emb.vocab_size(),
            'episodes': ep_stats.get('total', 0),
            'semantic_facts': sem_stats.get('facts', 0),
            'trainings': self.total_trainings,
            'queries': self.total_queries,
            'working_memory_turns': self.working.turn_count(),
            'conversation_patterns': len(self.conv_learner.conversation_db['successful_patterns']),
            'llm_available': self.llm_available,
            'llm_model': self.llm_model,
            'current_topic': self.working.current_topic(),
            'total_parameters': self.total_parameters
        }
    
    def save_all(self):
        """Guarda TODO - local Y MongoDB"""
        # â”€â”€ Archivos locales â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        self.rank_net.save(f'{MODEL_DIR}/rank_net.pkl')
        self.intent_net.save(f'{MODEL_DIR}/intent_net.pkl')
        self.context_net.save(f'{MODEL_DIR}/context_net.pkl')
        self.sentiment_net.save(f'{MODEL_DIR}/sentiment_net.pkl')
        self.meta_net.save(f'{MODEL_DIR}/meta_net.pkl')
        self.conv_learner._save_quality_net()
        self.conv_learner._save_conversations()
        self.emb.save()
        self.episodic.save()
        self.semantic.save()
        
        with open(f'{DATA_DIR}/meta.json', 'w') as f:
            json.dump({
                'total_queries': self.total_queries,
                'total_trainings': self.total_trainings
            }, f)
        
        # â”€â”€ MongoDB â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if MONGO_OK and _mongo_db is not None:
            try:
                # Meta
                _mongo_db.meta.update_one({'_id': 'nexus_meta'}, {'$set': {
                    'total_queries': self.total_queries,
                    'total_trainings': self.total_trainings,
                    'ts': time.time()
                }}, upsert=True)
                
                # Episodios
                if self.episodic.episodes:
                    eps_docs = []
                    for ep in self.episodic.episodes[-200:]:
                        doc = {k: v for k, v in ep.items() if k != 'emb'}
                        eps_docs.append(doc)
                    
                    _mongo_db.episodic.delete_many({})
                    _mongo_db.episodic.insert_many(eps_docs)
                
                # Semantic
                _mongo_db.semantic.update_one({'_id': 'semantic'}, {'$set': {
                    'facts': self.semantic.facts,
                    'preferences': self.semantic.preferences,
                    'query_clusters': self.semantic.query_clusters
                }}, upsert=True)
                
                # Patterns
                _mongo_db.patterns.update_one({'_id': 'patterns'}, {'$set': {
                    'successful': self.conv_learner.conversation_db['successful_patterns'][-500:],
                    'failed': self.conv_learner.conversation_db['failed_patterns'][-200:],
                    'ts': time.time()
                }}, upsert=True)
                
            except Exception as e:
                print(f"[MongoDB] Error guardando: {e}", file=sys.stderr, flush=True)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #  FUNCIONES DE ENTRENAMIENTO REAL - BACKPROPAGATION ACTIVO
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def train_from_feedback(self, query: str, result: dict, helpful: bool):
        """âœ… ENTRENA rank_net con feedback del usuario - BACKPROPAGATION REAL"""
        try:
            emb_q = self.emb.embed(query)
            emb_r = self.emb.embed(result.get('title', '') + ' ' + result.get('description', ''))
            
            # Features
            feats = np.array([
                len(result.get('title', '')),
                len(result.get('description', '')),
                1.0 if 'wikipedia' in result.get('url', '') else 0.0,
                result.get('_position', 1) / 10.0
            ])
            
            inp = np.concatenate([emb_q, emb_r, feats]).reshape(1, -1)
            target = np.array([[1.0 if helpful else 0.0]], dtype=np.float32)
            
            # âœ… BACKPROPAGATION REAL
            loss = self.rank_net.train_step(inp, target)
            
            self.total_trainings += 1
            
            if self.total_trainings % 10 == 0:
                print(f"[RankNet] Training #{self.total_trainings}, Loss: {loss:.4f}", file=sys.stderr, flush=True)
            
            self.save_all()
            
            return {'loss': float(loss), 'trainings': self.total_trainings}
        except Exception as e:
            print(f"[RankNet] Error entrenando: {e}", file=sys.stderr, flush=True)
            return {'loss': 0.0, 'trainings': self.total_trainings}
    
    def learn_from_click(self, query: str, url: str, position: int,
                         dwell_time: float, bounced: bool):
        """âœ… Aprende de clicks Y ENTRENA la red"""
        reward_delta = 0.0
        
        if dwell_time > 30 and not bounced:
            reward_delta = 0.2  # Buen resultado
        elif dwell_time > 10:
            reward_delta = 0.1  # Resultado OK
        elif bounced or dwell_time < 5:
            reward_delta = -0.1  # Mal resultado
        
        # Actualizar reward en episodios
        self.episodic.update_reward(query, url, reward_delta)
        
        # Actualizar preferencias semÃ¡nticas
        if reward_delta > 0:
            domain = url.split('//')[-1].split('/')[0]
            self.semantic.update_preference(f'domain:{domain}', reward_delta * 0.1)
        
        # âœ… ENTRENAR rank_net basado en el click
        # Buscar el resultado clickeado en episodios recientes
        for ep in reversed(self.episodic.episodes[-50:]):
            if ep.get('query') == query:
                for res in ep.get('results', []):
                    if res.get('url') == url:
                        # Este fue clickeado - entrenar como positivo
                        helpful = reward_delta > 0
                        self.train_from_feedback(query, res, helpful)
                        break
                break
        
        self.save_all()
    
    def learn(self, message: str, response: str, was_helpful: bool = True, search_results: list = []):
        """âœ… Aprende de feedback general - NUEVA FUNCIÃ“N"""
        try:
            # Entrenar quality net
            msg_emb = self.emb.embed(message)
            resp_emb = self.emb.embed(response)
            quality = 0.8 if was_helpful else 0.3
            
            self.conv_learner.train_quality_net(msg_emb, resp_emb, quality)
            
            # Si hay resultados de bÃºsqueda, entrenar rank_net
            if search_results:
                for result in search_results[:3]:  # Top 3
                    self.train_from_feedback(message, result, was_helpful)
            
            # Aprender patrÃ³n conversacional
            feedback_score = 0.8 if was_helpful else 0.2
            self.conv_learner.learn_from_interaction(message, response, feedback_score)
            
            self.total_trainings += 1
            self.save_all()
            
            print(f"[Brain] Aprendizaje completado. Trainings: {self.total_trainings}", file=sys.stderr, flush=True)
            
        except Exception as e:
            print(f"[Brain] Error en learn: {e}", file=sys.stderr, flush=True)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  SERVIDOR JSON - STDIN/STDOUT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    """Servidor JSON sobre stdin/stdout"""
    brain = NexusBrain()
    print("âœ… [Brain] Listo para recibir comandos JSON", file=sys.stderr, flush=True)
    print("âœ“ Brain listo", flush=True)  # seÃ±al a stdout â†’ server.js activa brain.ready
    
    for line in sys.stdin:
        line = line.strip()
        if not line:
            continue
        
        try:
            req = json.loads(line)
            action = req.get('action', 'process')
            request_id = req.get('_requestId')
            
            if action == 'process':
                message = req.get('message', '')
                history = req.get('conversation_history', [])
                results = req.get('search_results')
                conv_id = req.get('conversation_id')
                
                response = brain.process_query(message, history, results, conv_id)
                response['_requestId'] = request_id
                print(json.dumps(response, ensure_ascii=False), flush=True)
            
            elif action == 'click':
                brain.learn_from_click(
                    req.get('query', ''),
                    req.get('url', ''),
                    req.get('position', 1),
                    req.get('dwell_time', 0),
                    req.get('bounced', False)
                )
                print(json.dumps({'status': 'ok', '_requestId': request_id}), flush=True)
            
            elif action == 'learn':
                # âœ… NUEVA ACCIÃ“N - Maneja feedback general
                brain.learn(
                    req.get('message', ''),
                    req.get('response', ''),
                    req.get('was_helpful', True),
                    req.get('search_results', [])
                )
                print(json.dumps({'status': 'ok', '_requestId': request_id}), flush=True)
            
            elif action == 'stats':
                stats = brain._activity_report()
                stats['_requestId'] = request_id
                print(json.dumps(stats, ensure_ascii=False), flush=True)
            
            else:
                print(json.dumps({'error': f'Unknown action: {action}', '_requestId': request_id}), flush=True)
        
        except json.JSONDecodeError as e:
            print(json.dumps({'error': f'JSON decode error: {e}'}), flush=True, file=sys.stderr)
        except Exception as e:
            print(json.dumps({'error': str(e)}), flush=True, file=sys.stderr)
            import traceback
            traceback.print_exc(file=sys.stderr)

if __name__ == '__main__':
    main()
