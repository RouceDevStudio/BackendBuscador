# ğŸš€ GUÃA DE INSTALACIÃ“N NEXUS v3 EN TERMUX

## ğŸ“± PASO 1: Instalar dependencias en Termux

```bash
# Actualizar paquetes
pkg update && pkg upgrade -y

# Instalar Python y Node.js
pkg install python nodejs git -y

# Instalar compilador C (necesario para NumPy)
pkg install clang make -y

# Instalar dependencias de Python cientÃ­ficas
pkg install python-numpy -y

# O si prefieres compilar desde pip:
pip install --upgrade pip
pip install numpy

# Instalar dependencias de Node.js
npm install
```

## âš ï¸ SOLUCIÃ“N AL ERROR DE NUMPY

El error que ves (`ModuleNotFoundError: No module named 'numpy'`) ocurre porque:

1. **NumPy no estÃ¡ instalado** en tu entorno de Python
2. **EstÃ¡s usando Python del sistema** en lugar del de Termux

### SoluciÃ³n rÃ¡pida:
```bash
# OpciÃ³n 1: Instalar desde pkg (mÃ¡s rÃ¡pido, recomendado para Termux)
pkg install python-numpy

# OpciÃ³n 2: Instalar desde pip
pip install numpy --no-cache-dir

# Verificar instalaciÃ³n
python3 -c "import numpy; print(numpy.__version__)"
```

## ğŸ“¦ PASO 2: Configurar variables de entorno

Crea un archivo `.env` en la raÃ­z del proyecto:

```bash
# Motor de lenguaje (elige UNO)
# OpciÃ³n 1: Groq (recomendado - rÃ¡pido y gratuito)
GROQ_API_KEY=tu_api_key_aqui
GROQ_MODEL=llama-3.3-70b-versatile

# OpciÃ³n 2: Ollama (local, pero pesado para mÃ³vil)
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2

# Base de datos (opcional)
# MONGODB_URI=mongodb://localhost:27017
# MONGODB_DB_NAME=nexus

# Puerto
PORT=3000
```

### CÃ³mo obtener API key de Groq (GRATIS):
1. Ve a https://console.groq.com
2. Crea una cuenta
3. Ve a "API Keys"
4. Crea una nueva key y cÃ³piala
5. PÃ©gala en el archivo `.env`

## ğŸ§  PASO 3: Iniciar el servidor

```bash
# Desde la carpeta del proyecto
cd nexus_v3

# Instalar dependencias de Node.js
npm install

# Iniciar servidor
node server.js
```

## ğŸ“± PASO 4: Acceder desde el navegador

```bash
# En Termux, el servidor se ejecuta en:
http://localhost:3000

# O desde tu navegador mÃ³vil:
# Abre Chrome/Firefox y ve a: localhost:3000
```

## ğŸ”§ SOLUCIÃ“N A PROBLEMAS COMUNES

### 1. Error "Brain cerrÃ³ (code=1)"
```bash
# Instalar NumPy correctamente
pkg install python-numpy -y

# Verificar que Python encuentra NumPy
python3 -c "import numpy as np; print(np.__version__)"
```

### 2. Error "Cannot find module 'dotenv'"
```bash
npm install dotenv express cors axios cheerio mongodb
```

### 3. Puerto 3000 ocupado
```bash
# Cambiar puerto en .env
PORT=8080

# O matar proceso anterior
pkill -f "node server.js"
```

### 4. "LLM no conectado"
Tienes dos opciones:

**OpciÃ³n A: Usar Groq (RECOMENDADO para mÃ³vil)**
```bash
# Agregar a .env
GROQ_API_KEY=tu_key_aqui
GROQ_MODEL=llama-3.3-70b-versatile
```

**OpciÃ³n B: Usar Ollama (requiere mÃ¡s recursos)**
```bash
# Instalar Ollama en Termux (experimental)
pkg install ollama -y
ollama serve &
ollama pull llama3.2
```

## ğŸ“Š ARQUITECTURA DE NEXUS

```
nexus_v3/
â”œâ”€â”€ server.js          # Servidor Express (Node.js)
â”œâ”€â”€ neural/
â”‚   â”œâ”€â”€ brain.py       # Cerebro principal + LLM
â”‚   â”œâ”€â”€ network.py     # Redes neuronales (ranking + intent)
â”‚   â”œâ”€â”€ embeddings.py  # Embeddings de n-gramas
â”‚   â””â”€â”€ memory.py      # Memoria (episÃ³dica + semÃ¡ntica + trabajo)
â”œâ”€â”€ public/
â”‚   â””â”€â”€ index.html     # Interfaz web (ahora responsive!)
â”œâ”€â”€ models/            # Pesos de las redes neuronales
â”œâ”€â”€ data/              # Memoria persistente
â””â”€â”€ .env               # Variables de entorno

FLUJO:
Usuario â†’ index.html â†’ server.js â†’ brain.py â†’ LLM (Groq/Ollama)
                          â†“
                    Redes neuronales
                    + Memoria
                    + Web search
```

## ğŸ¨ MEJORAS IMPLEMENTADAS

### âœ… DiseÃ±o Responsive
- MenÃº hamburguesa para mÃ³viles
- Sidebar deslizable
- Texto adaptable
- Touch-friendly
- Safe area para iOS

### âœ… Soporte Groq
- API key en .env
- Modelos rÃ¡pidos (70B)
- Gratis (lÃ­mites generosos)
- Sin instalaciÃ³n local

### âœ… Fallback sin NumPy
- Si NumPy falla, usa listas Python
- Funciona (mÃ¡s lento) sin dependencias

## ğŸš€ CONSEJOS DE RENDIMIENTO

### Para Termux en mÃ³vil:
1. **Usa Groq en lugar de Ollama** (mucho mÃ¡s ligero)
2. **Cierra apps en segundo plano** para liberar RAM
3. **Usa modo de bajo consumo** si es posible
4. **No ejecutes entrenamientos masivos** en mÃ³vil

### Monitorear recursos:
```bash
# Ver uso de CPU/RAM
top

# Ver procesos Python
ps aux | grep python
```

## ğŸ› DEBUG

Si algo no funciona:

```bash
# Ver logs del servidor
node server.js

# Ver logs de Python directamente
python3 neural/brain.py

# Verificar todas las dependencias
npm list
pip list | grep numpy
```

## ğŸ“ CONTACTO

Si tienes problemas:
1. Verifica que NumPy estÃ© instalado: `python3 -c "import numpy"`
2. Verifica que el .env tenga GROQ_API_KEY
3. Revisa los logs en la terminal

## ğŸ¯ PRÃ“XIMOS PASOS

Una vez funcionando:
1. Experimenta con diferentes modelos de Groq
2. Ajusta la temperatura y parÃ¡metros en brain.py
3. Entrena las redes con tus conversaciones
4. Explora la memoria episÃ³dica y semÃ¡ntica

Â¡Disfruta de tu IA personal! ğŸ§ âœ¨
